[["index.html", "Learning LogBook Tree phenology analysis with R Chapter 1 Introduction", " Learning LogBook Tree phenology analysis with R Philipp Münker 2023-01-10 Chapter 1 Introduction In this learning Logbook, all units from the Tree phenology analysis with R module are documented. In addition to the tasks set at the end of each learning unit, this work is supplemented with additional materials and analyses. This is done using weather data taken from my own weather station. The corresponding data can be found at the following link: https://wettermuehle.de. Access data can be requested if desired. "],["tree-phenology.html", "Chapter 2 Tree phenology", " Chapter 2 Tree phenology If we consider fruit trees, their annual cycle can generally be described relatively easily. Starting in autumn, it is observed that almost all fruit trees shed their leaves and go into winter without foliage. Already in the autumn, the formation of the bud can often be observed. This bud then remains in a kind of winter dormancy throughout the winter and begins to grow with increasing temperatures in the spring. This process is usually followed by the flowering of the fruit trees with subsequent leaf development. Later in the year, fruits establish themselves from the buds, which mature at different times of the year. But how does the tree know when it can begin flowering induction and no longer expect strong frost? This can be described with the concept of dormancy. This can be divided into 4 phases. Tree dormancy Dormancy establishment Endodormancy Ecodormancy Growth resumption Dormacy establishment Controlled by tempeature and photoperiod. Endodormancy Controlled by plant endogenous factors. Plants unable to growth even under favorable environmental conditions. Ecodormancy After a certain level of chill, endodormancy has been overcome and buds recover the capacity to grow. Trees become acclimated to freezing tolerance and are not deeply dormant, but growth is still prevented by unsuitable environmental conditions. Temperature is the most important driver in this process. "],["treedormancy.html", "Chapter 3 Tree dormancy 3.1 Task 1 3.2 Task 2 3.3 Task 3", " Chapter 3 Tree dormancy 3.1 Task 1 Put yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods? Please justify your answer. Long-term phenological data does not exist, so a statistical approach is not optimal for newly released cultivars. It is better to work with an empirical approach. To do this, collect flower buds and place shoots in a chamber for 10 days under favorable conditions (temperature between 20 and 25 degrees). After 10 days, measure the weight of the shoots in the chamber and the shoots without the chamber. If the weight difference is greater than 30%, the cultivar is considered non-dormant. Otherwise, it is considered dormant 3.2 Task 2 Which are the advantages (2) of the BBCH scale compared with earlies scales? Not all parts of a tree are in the same development stage. Early scales only record the predominant state of the fruit tree. General principles for the design of a scale for plant growth stages include: Growth stages are easily recognizable under field conditions Growth stages are graded in the order of appearance (early scales do not do this) Two-digit code: Principal growth stages | Secondary growth stages Applicable for all cereals in all parts of the world. (Old scales can only be used for a specific group/fruit) 3.3 Task 3 Classify the following phenological stages of sweet cherry according to the BBCH scale: Picture 1 BBCH =55; Picture 2 BBCH =67; Picture 3 BBCH =89 "],["climate-change-and-impact-projection.html", "Chapter 4 Climate change and impact projection 4.1 Task 1 4.2 Task 2", " Chapter 4 Climate change and impact projection 4.1 Task 1 List the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate Table 4.1: Drivers of Climate Change Drivers of climate change Sun Aerosols Clouds Ozone Surface albedo Greenhouse gases The most important factor that currently has the greatest influence on climate and climate change is greenhouse gases. The most important greenhouse gases are water vapor, (carbon dioxide) CO2, (methane) CH4, and (nitrous oxides) N2O. Greenhouse gases can only absorb radiation of certain wavelengths. They absorb radiation with long wavelengths, which comes from the Earth’s surface in the form of infrared radiation emitted by the warm Earth’s surface. This radiation cannot leave the atmosphere and is trapped by the greenhouse gases, which returns it back to the Earth. 4.2 Task 2 Explain briefly what is special about temperature dynamics of the recent decades, and why we have good reasons to be concerned Over the past decades and throughout the last century, the temperature has been rising worldwide. Initially, this increase was relatively slow. The ten warmest years worldwide since 1880 were all measured after the millennium. The five warmest years worldwide were all recorded after 2014. This effect is also noticeable in Germany. Here, too, the ten warmest years were all measured after 2000, with one exception. If one places the temperature increase of the last decades in the climate history of the last one million years, it can be seen that there has never been such a strong temperature increase over such a relatively short period of time. This rapid rise in temperature is developing its own dynamic. For example, high temperatures in the tundra cause the permafrost to thaw, releasing a large amount of CO2, a greenhouse gas that promotes even faster warming. "],["manual-chill-analysis.html", "Chapter 5 Manual Chill Analysis 5.1 Task 1 5.2 Task 2 5.3 Task 3", " Chapter 5 Manual Chill Analysis The Winters_hours_gaps data set has the columns: Year, Month, Day, Hour, Temp_gaps, Temp. First, the function cleaned_data is used to remove unnecessary columns such as Temp_gaps() from the data set. #Clean Function cleaned_data = function(data_source) { data_source = data_source[, c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;, &quot;Hour&quot;, &quot;Temp&quot;)] return(data_source) } # Apply Function to Winters_hours_gaps kable(head(cleaned_data(data_source = Winters_hours_gaps)), caption = &quot;Cleaned Dataset: Winters_hours_gaps&quot;)%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 5.1: Cleaned Dataset: Winters_hours_gaps Year Month Day Hour Temp 2008 3 3 10 15.127 2008 3 3 11 17.153 2008 3 3 12 18.699 2008 3 3 13 18.699 2008 3 3 14 18.842 2008 3 3 15 19.508 5.1 Task 1 Write a basic function that calculates warm hours (&gt;25°C) WH = function(hourtemps) { hourtemps[, &quot;warm_hours&quot;] &lt;- hourtemps$Temp &gt;= 25.0 return(hourtemps) } 5.2 Task 2 Apply this function to the Winters_hours_gaps dataset # have a look to the data set kable(head(Winters_hours_gaps),caption = &quot;Example Dataset: Winters_hours_gaps&quot;)%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 5.2: Example Dataset: Winters_hours_gaps Year Month Day Hour Temp_gaps Temp 2008 3 3 10 15.127 15.127 2008 3 3 11 17.153 17.153 2008 3 3 12 18.699 18.699 2008 3 3 13 18.699 18.699 2008 3 3 14 18.842 18.842 2008 3 3 15 19.508 19.508 # Apply Function hourtemps = cleaned_data(data_source = Winters_hours_gaps) kable(head(WH(hourtemps = hourtemps)))%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Year Month Day Hour Temp warm_hours 2008 3 3 10 15.127 FALSE 2008 3 3 11 17.153 FALSE 2008 3 3 12 18.699 FALSE 2008 3 3 13 18.699 FALSE 2008 3 3 14 18.842 FALSE 2008 3 3 15 19.508 FALSE 5.3 Task 3 Extend this function, so that it can take start and end dates as inputs and sums up warm hours between these dates warm_hours_function = function(Input_Data, S_Jahr, S_Monat, S_Tag, S_Stunde, E_Jahr, E_Monat, E_Tag, E_Stunde) { Start_Date &lt;- which( hourtemps$Year == S_Jahr &amp; hourtemps$Month == S_Monat &amp; hourtemps$Day == S_Tag &amp; hourtemps$Hour == S_Stunde ) End_Date &lt;- which( hourtemps$Year == E_Jahr &amp; hourtemps$Month == E_Monat &amp; hourtemps$Day == E_Tag &amp; hourtemps$Hour == E_Stunde ) # Apply Function Warm Hours (WH) hourtemps = WH(hourtemps = Input_Data) # Calculate warm_hours warm_hours = sum(hourtemps$warm_hours[Start_Date:End_Date]) return(cat(&quot;The number of heat hours is:&quot;, paste(warm_hours))) } warm_hours_function( Input_Data = hourtemps, S_Jahr = 2008, S_Monat = 5, S_Tag = 1, S_Stunde = 12, E_Jahr = 2008, E_Monat = 8, E_Tag = 31, E_Stunde = 12 ) ## The number of heat hours is: 957 "],["chill-models.html", "Chapter 6 Chill Models 6.1 Task 1 6.2 Task2 6.3 Task3", " Chapter 6 Chill Models Counting chill hours can be done in various ways. ChillR offers some functions for this purpose. The simplest function for this is the Chilling_Hours() function. It records one chill hour for every temperature between 0 and 7.2 degrees. A slightly more complex function is the Utah_Model() function. It evaluates the measured temperatures and decides whether a full chill hour was reached or only half. For example, if the temperature is between 1 and 2 degrees, one chill hour has been reached. If it is between 3 and 4 degrees, two chill hours are recorded. The Dynamic_model() function is the most complex function. It is taken from an Excel sheet. The chilling() function combines the functions described above and presents the results in an overview. 6.1 Task 1 Run the chilling() function on the Winters_hours_gap dataset # run chilling function on Winters_hours_gap dataset output = chilling(make_JDay(Winters_hours_gaps), Start_JDay = 90, End_JDay = 100) kable(output, caption =&quot;chilling function on Winters_hours_gap&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 6.1: chilling function on Winters_hours_gap Season End_year Season_days Data_days Perc_complete Chilling_Hours Utah_Model Chill_portions GDH 2007/2008 2008 11 11 100 40 15.5 2.009147 2406.52 6.2 Task2 Create your own temperature-weighting chill model using the step_model() function The step_model function has two arguments that the user can pass. One is a dataset of temperature data HourTemp and the other is a data.frame() (df) consisting of lower, upper, and weight. A pre-defined lower temperature range from, for example, -1000 °C to 0 °C is set, with all temperatures within this range being assigned a weight of 0. Assuming that hourly temperature data is provided as input, the temperature can be multiplied by the corresponding weight to obtain the amount of “chillhours”. For example: -1 °C is within the range [-1000, 0] == 0, resulting in 0 chillhours. Another argument is summ. If summ = TRUE, the cumulative chillhours over a defined period will be output. If summ = FALSE, the weights of the chillhours will be output. step_model = function (HourTemp, df = data.frame( lower = c(-1000, 1.4, 2.4, 9.1, 12.4, 15.9, 18), upper = c(1.4, 2.4, 9.1, 12.4, 15.9, 18, 1000), weight = c(0, 0.5, 1, 0.5, 0, -0.5, -1) ), summ = TRUE) { lower &lt;- df$lower upper &lt;- df$upper weight &lt;- df$weight if (summ == TRUE) return(cumsum(sapply(HourTemp, function(x) weight[which(x &gt; lower &amp; x &lt;= upper)]))) else return(sapply(HourTemp, function(x) weight[which(x &gt; lower &amp; x &lt;= upper)])) } Here, only an “own data field” is defined with its own limits that have their own weight. For example, from -100 °C to 0 °C, the weight is set to 0. In this case, no “chillhour” occurs. If the temperature is between 0 °C and 2 °C, the weight of the “chillhour” is 0.5. In this case, half a “chillhour” occurs. own_df = data.frame (lower = c(-100,0, 2, 4, 5, 6, 7 ), upper = c( 0, 2, 4, 5, 6, 7, 100 ), weight = c( 0, 0.5,1, 1.5,1, 0.5, 0 )) After the dataframe with your own weights has been created, it can be implemented into the step_model() function. use_step_model = function(x){step_model(x,own_df)} # quick aplly use_step_model(x = Winters_hours_gaps$Temp)[1:100] ## [1] 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.5 ## [16] 1.0 1.0 1.0 1.5 2.5 3.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 ## [31] 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 ## [46] 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 ## [61] 4.5 5.0 5.5 6.0 7.0 8.5 9.5 10.5 11.5 12.5 13.0 13.0 13.0 13.0 13.0 ## [76] 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.5 14.0 15.0 16.5 18.0 ## [91] 19.5 21.0 22.0 23.0 23.0 23.0 23.0 23.0 23.0 23.0 6.3 Task3 Run this model on the Winters_hours_gaps dataset using the tempResponse() function The tempResponse() function can display and summarize some chill models. Here is the model weather_mill() our own chilling model which is created by the step_model(). The modified step_model() function is renamed to use_step_model() and passed as a parameter to the tempResponse function (weather_mill = use_step_model). output &lt;- tempResponse( make_JDay(Winters_hours_gaps), Start_JDay = 30, End_JDay = 100, models = list( Chill_Portions = Dynamic_Model, GDH = GDH, weather_mill = use_step_model, # own model weather_mill Utah_Model = Utah_Model ) ) # display result kable(output, caption = &quot;Summarized some models&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 6.2: Summarized some models Season End_year Season_days Data_days Perc_complete Chill_Portions GDH weather_mill Utah_Model 2007/2008 2008 71 37.58333 52.93427 5.930439 8392.585 84 49.5 If the Utah Model is included, which is based on the default settings of the Step Model, a clear difference between the modified Step Model and the Utah Model can be observed. "],["making-hourly-temperatures.html", "Chapter 7 Making hourly temperatures 7.1 Task 1 7.2 Task 2", " Chapter 7 Making hourly temperatures 7.1 Task 1 Choose a location of interest, find out its latitude and produce plots of daily sunrise, sunset and daylength First, I would like to compare the lengths of days among locations of interest. I have selected Glogau in Poland, Zülpich in Germany, Tenerife in Spain, Moscow in Russia, and Karkaralinsk in Kazakhstan. # initialize the variables with daylength, sunrise and sunset by the function daylength Glogau &lt;- daylength(latitude = 51.40, JDay = 1:365) Teneriffa &lt;- daylength(latitude = 28.19, JDay = 1:365) Zuelpich &lt;- daylength(latitude = 50.42, JDay = 1:365) Moskau &lt;- daylength(latitude = 55.45, JDay = 1:365) Karkaralinsk &lt;- daylength(latitude = 49.24, JDay = 1:365) # Create a dataframe consisting of the variables &quot;base&quot; (days 1 to 365) and the # respective locations and containing only the day length for each location. df &lt;- data.frame( base = seq(length(Glogau[[1]])), Glogau = Glogau[[3]], Teneriffa = Teneriffa[[3]], Zülpich = Zuelpich[[3]], Moskau = Moskau[[3]], Karkaralinsk = Karkaralinsk[[3]] ) kable(head(df), caption = &quot;Differnt Locations&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 7.1: Differnt Locations base Glogau Teneriffa Zülpich Moskau Karkaralinsk 1 7.930050 10.38197 8.086864 7.175796 8.265160 2 7.948054 10.38872 8.104044 7.198073 8.281428 3 7.967737 10.39612 8.122830 7.222407 8.299217 4 7.989077 10.40415 8.143199 7.248768 8.318509 5 8.012048 10.41281 8.165129 7.277120 8.339282 6 8.036625 10.42209 8.188595 7.307424 8.361515 # create a pivot table df_long &lt;- pivot_longer(df, -&quot;base&quot;, names_to = &quot;Location&quot;, values_to = &quot;daylength&quot;) kable(head(df_long)) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) base Location daylength 1 Glogau 7.930050 1 Teneriffa 10.381965 1 Zülpich 8.086864 1 Moskau 7.175796 1 Karkaralinsk 8.265160 2 Glogau 7.948054 # plot the result with ggplot ggplot(df_long, aes(x = base, y = daylength, groupe = Location)) + geom_line(aes(color = Location), lwd = 1.0) + ggtitle(&quot;Different day lengths in different places&quot;) + labs(x = &quot;Days&quot;, y = &quot;Daylength [h]&quot;) + theme_gray(base_size = 15) Create a summary of the sunrise, sunset, and day length for Moscow. Days &lt;- daylength(latitude = 55.45, JDay = 1:365) Days_df &lt;- data.frame( JDay = 1:365, Sunrise = Days$Sunrise, Sunset = Days$Sunset, Daylength = Days$Daylength ) Days_df&lt;-melt(Days_df, id=c(&quot;JDay&quot;)) Show the final result ggplot(Days_df, aes(x = JDay, y = value)) + geom_line(lwd = 1.5, color = &quot;red&quot;) + facet_grid(cols = vars(variable)) + ylab(&quot;Time of Day / Daylength (Hours)&quot;) + theme_bw(base_size = 20) + ggtitle(&quot;Sunrise, Sunset and Daylength of Moskau&quot;) 7.2 Task 2 Produce an hourly dataset, based on idealized daily curves, for the KA_weather dataset (included in chillR) The following two tasks were performed in a modified form. In order to demonstrate the application of the chillR package, it was decided to use a currently active weather station and use its data as a basis. Data on the weather station can be found in the table below. Here is a picture of the weather station: Table 7.2: Weather Station Fuessenich Location State GPS Gauß_Krüger Zuelpich - Fuessenich North Rhine-Westphalia 50.69527026369208, 6.615666577711913 Rechtswert:2543500 Hochwert: 5617798 First, corresponding data must be read in. The data are already prepared. Zuelpich_hourly = read.table( &quot;weather_data/Weather_Zuelpich_2019_hourly.csv&quot;, header = TRUE, sep = &quot;,&quot; ) Zuelpich_min_max = read.table(&quot;weather_data/Weather_Zuelpich_2019.csv&quot;, header = TRUE, sep = &quot;,&quot;) zuelpich_april = Zuelpich_hourly %&gt;% filter(&quot;2019-04-01 00:00:00&quot; &lt; date) %&gt;% filter(&quot;2019-04-05 00:00:00&quot; &gt; date) zuelpich_april$date_new &lt;- as.POSIXct(zuelpich_april[, 3]) zuelpich_april$date_newnew = as.Date(zuelpich_april[, 3]) kable(head(zuelpich_april), caption = &quot;Dataset: zuelpich_april&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 7.3: Dataset: zuelpich_april X temperature date date_new date_newnew 1412 3.4350000 2019-04-01 01:00:00 2019-04-01 01:00:00 2019-04-01 1413 2.0900000 2019-04-01 02:00:00 2019-04-01 02:00:00 2019-04-01 1414 1.2616667 2019-04-01 03:00:00 2019-04-01 03:00:00 2019-04-01 1415 0.6150000 2019-04-01 04:00:00 2019-04-01 04:00:00 2019-04-01 1416 0.0583333 2019-04-01 05:00:00 2019-04-01 05:00:00 2019-04-01 1417 -0.3566667 2019-04-01 06:00:00 2019-04-01 06:00:00 2019-04-01 Next, the lows and highs for the corresponding days must be determined from the data set containing hourly data. final &lt;- zuelpich_april %&gt;% group_by(Tag = day(date_newnew)) %&gt;% summarise( Mittel = round(mean(temperature, na.rm = TRUE), digits = 1), Tmax = max(temperature), Tmin = min(temperature) ) kable(final, caption = &quot;Dataset:Tmean Tmax Tmin&quot;)%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 7.4: Dataset:Tmean Tmax Tmin Tag Mittel Tmax Tmin 1 7.7 17.810000 -0.420000 2 9.5 17.096667 2.693333 3 7.6 9.983333 5.481667 4 5.7 7.763333 3.566667 Next, the dataset containing hourly temperature values must be extended with a column that will later represent the daily high and low values. First, the new column Tmax_Tmin is filled with NAs. Then the maximum and minimum values are taken from the previously generated dataset final. These values are compared with the hourly values. If they match, the maximum or minimum value found is written to the previously created column Tmax_Tmin. In this way, the daily maximum and minimum values are placed in the table zuelpich_april at the same place where they were also measured. # generate new coloumn with NAs zuelpich_april$Tmax_Tmin = NA # match Tmin for (i in seq(1, nrow(zuelpich_april))) { for (j in seq(1, nrow(final))) { if (zuelpich_april$temperature[i] == final$Tmax[j]) { zuelpich_april$Tmax_Tmin[i] &lt;- final$Tmax[j] } } } # match Tmax for(i in seq(1, nrow(zuelpich_april))) { for (j in seq(1, nrow(final))) { if (zuelpich_april$temperature[i] == final$Tmin[j]) { zuelpich_april$Tmax_Tmin[i] &lt;- final$Tmin[j] } } } kable(zuelpich_april[1:25,], caption = &quot;Dataset: TmaxTminMatch&quot;)%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 7.5: Dataset: TmaxTminMatch X temperature date date_new date_newnew Tmax_Tmin 1412 3.4350000 2019-04-01 01:00:00 2019-04-01 01:00:00 2019-04-01 NA 1413 2.0900000 2019-04-01 02:00:00 2019-04-01 02:00:00 2019-04-01 NA 1414 1.2616667 2019-04-01 03:00:00 2019-04-01 03:00:00 2019-04-01 NA 1415 0.6150000 2019-04-01 04:00:00 2019-04-01 04:00:00 2019-04-01 NA 1416 0.0583333 2019-04-01 05:00:00 2019-04-01 05:00:00 2019-04-01 NA 1417 -0.3566667 2019-04-01 06:00:00 2019-04-01 06:00:00 2019-04-01 NA 1418 -0.4200000 2019-04-01 07:00:00 2019-04-01 07:00:00 2019-04-01 -0.42 1419 0.9666667 2019-04-01 08:00:00 2019-04-01 08:00:00 2019-04-01 NA 1420 3.9333334 2019-04-01 09:00:00 2019-04-01 09:00:00 2019-04-01 NA 1421 6.4183333 2019-04-01 10:00:00 2019-04-01 10:00:00 2019-04-01 NA 1422 9.2050000 2019-04-01 11:00:00 2019-04-01 11:00:00 2019-04-01 NA 1423 11.6483333 2019-04-01 12:00:00 2019-04-01 12:00:00 2019-04-01 NA 1424 13.0883333 2019-04-01 13:00:00 2019-04-01 13:00:00 2019-04-01 NA 1425 14.5100000 2019-04-01 14:00:00 2019-04-01 14:00:00 2019-04-01 NA 1426 16.2199999 2019-04-01 15:00:00 2019-04-01 15:00:00 2019-04-01 NA 1427 17.4650000 2019-04-01 16:00:00 2019-04-01 16:00:00 2019-04-01 NA 1428 17.8100000 2019-04-01 17:00:00 2019-04-01 17:00:00 2019-04-01 17.81 1429 16.8549999 2019-04-01 18:00:00 2019-04-01 18:00:00 2019-04-01 NA 1430 14.0283333 2019-04-01 19:00:00 2019-04-01 19:00:00 2019-04-01 NA 1431 10.4783333 2019-04-01 20:00:00 2019-04-01 20:00:00 2019-04-01 NA 1432 7.3850000 2019-04-01 21:00:00 2019-04-01 21:00:00 2019-04-01 NA 1433 6.1783334 2019-04-01 22:00:00 2019-04-01 22:00:00 2019-04-01 NA 1434 5.2233333 2019-04-01 23:00:00 2019-04-01 23:00:00 2019-04-01 NA 1435 4.9883333 2019-04-02 00:00:00 2019-04-02 00:00:00 2019-04-02 NA 1436 4.2500000 2019-04-02 01:00:00 2019-04-02 01:00:00 2019-04-02 NA After creating a new column containing only the Tmax and Tmin temperatures, a plot can be created that shows the measured temperature history and includes information on Tmax and Tmin. The red dots symbolize the daily temperature values for Tmax and Tmin, respectively. ggplot(data = zuelpich_april, aes(x = zuelpich_april[, 4], y = zuelpich_april[, 2])) + geom_line(size = 1.0, colour = &quot;darkgreen&quot;) + geom_point(aes(y = zuelpich_april$Tmax_Tmin), colour = &quot;red&quot;, size = 3.0) + labs(x = &quot;Date&quot;, y = &quot;Temperature (C°)&quot;) + ggtitle(&quot;1 to 5 April 2019 weather station Zuelpich&quot;) + theme_bw(base_size = 13) First, the dataset ZU_weather must be created. The columns DATE, Year, Month, Day, Tcontinue, and Temp_inter are created. The Temp_inter column contains temperature data with large gaps that must be interpolated between. ZU_weather = data.frame( DATE = zuelpich_april[, 4], Year = as.numeric(substr(zuelpich_april[, 4], 1, 4)), Month = as.numeric(substr(zuelpich_april[, 4], 6, 7)), Day = as.numeric(substr(zuelpich_april[, 4], 9, 10)), Tcontinue = zuelpich_april[, 2], Temp_inter = zuelpich_april[, 6] ) kable(ZU_weather[1:8,])%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) DATE Year Month Day Tcontinue Temp_inter 2019-04-01 01:00:00 2019 4 1 3.4350000 NA 2019-04-01 02:00:00 2019 4 1 2.0900000 NA 2019-04-01 03:00:00 2019 4 1 1.2616667 NA 2019-04-01 04:00:00 2019 4 1 0.6150000 NA 2019-04-01 05:00:00 2019 4 1 0.0583333 NA 2019-04-01 06:00:00 2019 4 1 -0.3566667 NA 2019-04-01 07:00:00 2019 4 1 -0.4200000 -0.42 2019-04-01 08:00:00 2019 4 1 0.9666667 NA The next step is to use the interpolate_gaps() function to calculate the missing temperatures between Tmax and Tmin. The function interpolate_gaps() returns a list with two entries. The first entry of the list contains the interpolated values, which can be accessed using $interp or [[1]]. The second entry, $missing, gives information on whether a value needs to be interpolated or if a real value is present. The function interpolate_gaps() linearly interpolates between gaps in the temperature records. The interpolated values are written directly to the Temp_inter column using the first list entry created by the interpolate_gaps() function. # interpolate between gaps in coloum Temp_inter ZU_weather$Temp_inter &lt;- interpolate_gaps(ZU_weather$Temp_inter)[[1]] # have a look at the first 10 entries kable(ZU_weather[1:10, ]) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) DATE Year Month Day Tcontinue Temp_inter 2019-04-01 01:00:00 2019 4 1 3.4350000 -0.420 2019-04-01 02:00:00 2019 4 1 2.0900000 -0.420 2019-04-01 03:00:00 2019 4 1 1.2616667 -0.420 2019-04-01 04:00:00 2019 4 1 0.6150000 -0.420 2019-04-01 05:00:00 2019 4 1 0.0583333 -0.420 2019-04-01 06:00:00 2019 4 1 -0.3566667 -0.420 2019-04-01 07:00:00 2019 4 1 -0.4200000 -0.420 2019-04-01 08:00:00 2019 4 1 0.9666667 1.403 2019-04-01 09:00:00 2019 4 1 3.9333334 3.226 2019-04-01 10:00:00 2019 4 1 6.4183333 5.049 Thus, all gaps in the column Temp_inter are filled by linear interpolation. The interpolation is performed between the gaps. The non-linear interpolation method considers the sun’s position at the respective location in the interpolation. In addition, the stack_hourly_temps() function requires a dataset as input that only contains Tmax and Tmin values. In this example, this dataset is called ZU_weather_min_max and consists of five columns: Year, Month, Day, Tmax, and Tmin. # create dataframe for non-linear interpolation ZU_weather_min_max = data.frame( Year = as.numeric(substr(Zuelpich_min_max[, 2], 1, 4)), Month = as.numeric(substr(Zuelpich_min_max[, 2], 6, 7)), Day = as.numeric(substr(Zuelpich_min_max[, 2], 9, 10)), Tmax = final[, 3], Tmin = final[, 4] ) kable(ZU_weather_min_max[1:10,])%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Year Month Day Tmax Tmin 2019 2 2 17.810000 -0.420000 2019 2 3 17.096667 2.693333 2019 2 4 9.983333 5.481667 2019 2 5 7.763333 3.566667 2019 2 6 17.810000 -0.420000 2019 2 7 17.096667 2.693333 2019 2 8 9.983333 5.481667 2019 2 9 7.763333 3.566667 2019 2 10 17.810000 -0.420000 2019 2 11 17.096667 2.693333 The function stack_hourly_temps() can be passed the entire dataset ZU_weather_min_max. This function sets the Tmax values to 6:00 PM and the Tmin values to 6:00 AM, without performing any interpolation between the times when the Tmax and Tmin values actually occurred. The resulting interpolation is written to a new dataset, ZU_hourly. A new column called DATE is then created in this dataset to store the date, and the first row is removed due to an index shift. ZU_hourly = stack_hourly_temps(ZU_weather_min_max, latitude = 50.4) ZU_hourly$hourtemps[, &quot;DATE&quot;] = ISOdate( ZU_hourly$hourtemps$Year, ZU_hourly$hourtemps$Month, ZU_hourly$hourtemps$Day, ZU_hourly$hourtemps$Hour ) ZU_hourly_mod = ZU_hourly[[1]][-1, ] kable(ZU_hourly_mod[1:10,])%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Year Month Day Tmax Tmin JDay Hour Temp DATE 609 2019 2 2 17.81 -0.42 33 1 -0.420000 2019-02-02 01:00:00 1217 2019 2 2 17.81 -0.42 33 2 -0.420000 2019-02-02 02:00:00 1825 2019 2 2 17.81 -0.42 33 3 -0.420000 2019-02-02 03:00:00 2433 2019 2 2 17.81 -0.42 33 4 -0.420000 2019-02-02 04:00:00 3041 2019 2 2 17.81 -0.42 33 5 -0.420000 2019-02-02 05:00:00 3649 2019 2 2 17.81 -0.42 33 6 -0.420000 2019-02-02 06:00:00 4257 2019 2 2 17.81 -0.42 33 7 -0.420000 2019-02-02 07:00:00 4865 2019 2 2 17.81 -0.42 33 8 2.355706 2019-02-02 08:00:00 5473 2019 2 2 17.81 -0.42 33 9 6.496980 2019-02-02 09:00:00 6081 2019 2 2 17.81 -0.42 33 10 10.253744 2019-02-02 10:00:00 Finally, a dataset is generated containing the actual measured temperature data, as well as the interpolated values calculated using both linear and non-linear interpolation. The results can be effectively visualized in a plot. # final_df = data.frame( # DATE = zuelpich_april[, 4], # Measured_Temp = zuelpich_april[, 2], # Linear_Interp = ZU_weather[, 6], # Non_Linear_Interp = ZU_hourly_mod[, 8] # ) #write.csv(final_df, &quot;weather_data/final_df_non_linear.csv&quot;) # read final dataframe final_df_m = read.table(&quot;weather_data/final_df_non_linear.csv&quot;, header = TRUE, sep = &quot;,&quot;) #remove index final_df_mx = final_df_m[, -1] #generate Date final_df_mx$DATE = as.POSIXct(final_df_mx$DATE) #create pivot table final_df_mod = pivot_longer(final_df_mx, -&quot;DATE&quot;, names_to = &quot;Method&quot;, values_to = &quot;Temperature&quot;) #plot final result and compare methods ggplot(data = final_df_mod, aes(x = DATE, y = Temperature , colour = Method)) + geom_line(lwd = 1.3) + labs(x = &quot;Date&quot;, y = &quot;Temperature (C°)&quot;) + ggtitle(&quot;1 to 5 April 2019 Zuelpich&quot;) + scale_color_manual(values = c(&quot;red&quot;, &quot;darkgreen&quot;, &quot;darkblue&quot;)) + #facet_wrap(vars(Method)) + theme_bw(base_size = 15) "],["getting-temperature-data.html", "Chapter 8 Getting temperature data 8.1 Task 1 8.2 Task 2 8.3 Task 3", " Chapter 8 Getting temperature data 8.1 Task 1 Choose a location of interest and find the 25 closest weather stations using the handle_gsod function I have decided to conduct a phonology analysis at a location in Poland. The city of Glogau, situated on the banks of the Oder, was chosen as the starting point. For more information about the location, the following website can be visited here. The climate at the location is relatively similar to Bonn, although the climate is generally more continental, which can be reflected in colder winters and drier, slightly warmer summers. Here is a picture of a typical landscape in Lower Silesia in Poland. Beautiful Glogau City Ok, here really beautiful old city of Glogau # station_list_poland = handle_gsod(action=&quot;list_stations&quot;, # location=c(16.5,51.39), # time_interval=c(1990,2020)) # kable(station_list_poland[1:10,]) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) # write.csv(station_list_poland,&quot;weather_data/Poland_station_list.csv&quot;,row.names=FALSE) list_poland_weather = read.table(&quot;weather_data/Poland_station_list.csv&quot;, header = TRUE, sep=&quot;,&quot;) kable(list_poland_weather[1:10,], caption = &quot;Station List&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 8.1: Station List chillR_code STATION.NAME CTRY Lat Long BEGIN END distance Overlap_years Perc_interval_covered 124170_99999 LUBIN MIASTO PL 51.417 16.200 19390810 19411231 21.09 0.00 0.00 124150_99999 LEGNICA PL 51.200 16.200 19370401 20221110 29.74 31.00 100.00 124250_99999 WROCLAW I PL 51.117 16.883 19280101 20220614 40.47 31.00 100.00 124240_99999 STRACHOWICE PL 51.103 16.886 19390102 20221110 41.78 31.00 100.00 124280_99999 WROCLAW/STRACHOWICE PL 51.100 16.883 20020601 20220901 41.91 18.59 59.95 124160_99999 WSCHOWA PL 51.800 16.317 19360102 19420630 47.35 0.00 0.00 124180_99999 LESZNO PL 51.833 16.533 19730101 20211212 49.34 31.00 100.00 125010_99999 MIROSLAWICE PL 50.950 16.767 19390901 19420628 52.39 0.00 0.00 125230_99999 SWIDNICA PL 50.850 16.483 19410114 19431231 60.09 0.00 0.00 125220_99999 SLEZA PL 50.867 16.717 19400414 19420630 60.13 0.00 0.00 8.2 Task 2 Download weather data for the most promising station on the list The most promising station for obtaining continuous weather recording is represented by the weather station in Leszno, located approximately 50 kilometers (by air) from Glogau. This location is listed as the seventh entry in the “Station List” table. To avoid constantly loading the weather data, it is stored in the weather_poland_leszno variable. The file is then saved as a CSV and read in using the read.table() function. # weather_poland_leszno &lt;- handle_gsod( # action = &quot;download_weather&quot;, # location = station_list_poland$chillR_code[7], # time_interval = c(1990, 2020)) # kable(weather_poland_leszno[[1]][[2]][1:10, ]) %&gt;% # kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) #write.csv(weather_poland_leszno[[1]][[2]],&quot;weather_data/Poland_leszno_weather.csv&quot;,row.names=FALSE) weather_poland_leszno_place = read.table(&quot;weather_data/Poland_leszno_weather.csv&quot;, header = TRUE, sep=&quot;,&quot;) kable(weather_poland_leszno_place[1:10, ], caption = &quot;Weather Data Leszno &quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 8.2: Weather Data Leszno DATE STN… WBAN YEAR MONTH DAY TEMP Count1 DEWP Count2 SLP Count3 STP Count4 VISIB Count5 WDSP Count6 MXSPD GUST MAX MaxFlag MIN MinFlag PRCP PrcpFlag SNDP FRSHTT Year Month Day 1990-01-01 12:00:00 124180 99999 1990 1 1 -1.1111111 7 28.6 7 1022.2 7 NA 0 1.1 7 1.9 7 3.9 NA -0.6111111 -2.000000 0.000 E NA 1000 1990 1 1 1990-01-02 12:00:00 124180 99999 1990 1 2 -1.7222222 8 25.9 8 1023.3 8 NA 0 1.5 8 3.2 8 5.8 NA -1.2777778 -2.111111 0.000 F NA 1000 1990 1 2 1990-01-03 12:00:00 124180 99999 1990 1 3 -1.7777778 7 25.6 7 1028.2 7 NA 0 1.9 7 3.6 7 5.8 NA -0.7777778 -2.611111 0.000 F NA 1000 1990 1 3 1990-01-04 12:00:00 124180 99999 1990 1 4 -2.4444444 7 22.5 7 1029.0 7 NA 0 2.9 7 6.1 7 11.7 NA -0.7777778 -5.277778 0.000 C NA 0 1990 1 4 1990-01-05 12:00:00 124180 99999 1990 1 5 -2.3888889 7 22.6 7 1026.5 6 NA 0 2.2 7 4.4 7 7.8 NA -0.3888889 -7.722222 0.000 D NA 0 1990 1 5 1990-01-06 12:00:00 124180 99999 1990 1 6 -4.7777778 7 21.3 7 1032.6 6 NA 0 1.4 7 2.5 7 3.9 NA 0.0000000 -7.000000 0.000 C NA 0 1990 1 6 1990-01-07 12:00:00 124180 99999 1990 1 7 -7.3333333 8 15.4 8 1033.4 8 NA 0 1.1 8 3.4 8 5.8 NA -2.7222222 -11.611111 0.000 D NA 0 1990 1 7 1990-01-08 12:00:00 124180 99999 1990 1 8 -4.5555556 8 18.0 8 1033.4 8 NA 0 1.6 8 4.6 8 7.8 NA 1.1111111 -10.500000 0.000 D NA 0 1990 1 8 1990-01-09 12:00:00 124180 99999 1990 1 9 0.8333333 6 33.1 6 1033.8 6 NA 0 0.7 6 6.6 5 7.8 NA 2.1111111 -1.777778 0.000 E NA 110000 1990 1 9 1990-01-10 12:00:00 124180 99999 1990 1 10 2.7222222 7 36.3 7 1030.9 6 NA 0 1.1 7 6.9 7 9.7 NA 3.2777778 1.500000 0.254 F NA 110000 1990 1 10 8.3 Task 3 Convert the weather data into chillR format # weather_pl &lt;- weather_poland_leszno$LESZNO[[2]] # cleaned_weather_pl &lt;- handle_gsod(weather_pl) # kable(cleaned_weather_pl[1:20,]) %&gt;% # kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) #write.csv(cleaned_weather_pl,&quot;weather_data/Poland_leszno_chillR_weather.csv&quot;,row.names=FALSE) cleaned_weather_pl_leszno = read.table(&quot;weather_data/Poland_leszno_chillR_weather.csv&quot;, header = TRUE, sep = &quot;,&quot;) kable(cleaned_weather_pl_leszno[1:10, ], caption = &quot;Cleaned Weather Data Leszno&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) Table 8.3: Cleaned Weather Data Leszno DATE Year Month Day Tmin Tmax Tmean Prec 1990-01-01 12:00:00 1990 1 1 -2.000000 -0.6111111 -1.1111111 0.000 1990-01-02 12:00:00 1990 1 2 -2.111111 -1.2777778 -1.7222222 0.000 1990-01-03 12:00:00 1990 1 3 -2.611111 -0.7777778 -1.7777778 0.000 1990-01-04 12:00:00 1990 1 4 -5.277778 -0.7777778 -2.4444444 0.000 1990-01-05 12:00:00 1990 1 5 -7.722222 -0.3888889 -2.3888889 0.000 1990-01-06 12:00:00 1990 1 6 -7.000000 0.0000000 -4.7777778 0.000 1990-01-07 12:00:00 1990 1 7 -11.611111 -2.7222222 -7.3333333 0.000 1990-01-08 12:00:00 1990 1 8 -10.500000 1.1111111 -4.5555556 0.000 1990-01-09 12:00:00 1990 1 9 -1.777778 2.1111111 0.8333333 0.000 1990-01-10 12:00:00 1990 1 10 1.500000 3.2777778 2.7222222 0.254 "],["filling-gaps-in-temperature-records.html", "Chapter 9 Filling gaps in temperature records 9.1 Task 1 9.2 Task 2 9.3 Task 3 9.4 Task 4 9.5 Task 5", " Chapter 9 Filling gaps in temperature records 9.1 Task 1 Use chillR functions to find out how many gaps you have in this dataset (even if you have none, please still follow all further steps) Leszno = read.csv(&quot;weather_data/Poland_leszno_chillR_weather.csv&quot;) # detected many gaps Leszno_QC = fix_weather(Leszno)$QC kable(Leszno_QC, caption = &quot;Quality Check for Data Leszno &quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.1: Quality Check for Data Leszno Season End_year Season_days Data_days Missing_Tmin Missing_Tmax Incomplete_days Perc_complete 1989/1990 1990 365 365 1 1 1 99.7 1990/1991 1991 365 365 26 26 26 92.9 1991/1992 1992 366 366 284 284 284 22.4 1992/1993 1993 365 365 140 140 140 61.6 1993/1994 1994 365 365 57 57 57 84.4 1994/1995 1995 365 365 4 4 4 98.9 1995/1996 1996 366 366 5 5 5 98.6 1996/1997 1997 365 365 75 75 75 79.5 1997/1998 1998 365 365 140 140 140 61.6 1998/1999 1999 365 365 39 39 39 89.3 1999/2000 2000 366 366 1 1 1 99.7 2000/2001 2001 365 365 23 23 23 93.7 2001/2002 2002 365 365 4 4 4 98.9 2002/2003 2003 365 365 1 1 1 99.7 2003/2004 2004 366 366 2 2 2 99.5 2004/2005 2005 365 365 365 365 365 0.0 2005/2006 2006 365 365 365 365 365 0.0 2006/2007 2007 365 365 365 365 365 0.0 2007/2008 2008 366 366 366 366 366 0.0 2008/2009 2009 365 365 365 365 365 0.0 2009/2010 2010 365 365 365 365 365 0.0 2010/2011 2011 365 365 365 365 365 0.0 2011/2012 2012 366 366 366 366 366 0.0 2012/2013 2013 365 365 365 365 365 0.0 2013/2014 2014 365 365 365 365 365 0.0 2014/2015 2015 365 365 365 365 365 0.0 2015/2016 2016 366 366 366 366 366 0.0 2016/2017 2017 365 365 365 365 365 0.0 2017/2018 2018 365 365 365 365 365 0.0 2018/2019 2019 365 365 365 365 365 0.0 2019/2020 2020 366 366 366 366 366 0.0 Upon closer examination, the seemingly promising location of Leszno exhibits many gaps in temperature data, particularly after 2005. These gaps must be filled with temperature data from neighboring stations. 9.2 Task 2 Create a list of the 25 closest weather stations using the handle_gsod function # station_list_close_to_leszno&lt;- # handle_gsod(action=&quot;list_stations&quot;,location=c(16.57,51.85),time_interval=c(1990,2020)) # write.csv(station_list_close_to_leszno,&quot;station_list_close_to_leszno.csv&quot; ) station_list_close_to_leszno = read.csv(&quot;station_list_close_to_leszno.csv&quot;) kable(station_list_close_to_leszno[1:10,], caption=&quot;List of GSOD weather stations close to Leszno&quot;)%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.2: List of GSOD weather stations close to Leszno X chillR_code STATION.NAME CTRY Lat Long BEGIN END distance Overlap_years Perc_interval_covered 4162 124180_99999 LESZNO PL 51.833 16.533 19730101 20211212 3.17 31.00 100.00 4160 124160_99999 WSCHOWA PL 51.800 16.317 19360102 19420630 18.31 0.00 0.00 4161 124170_99999 LUBIN MIASTO PL 51.417 16.200 19390810 19411231 54.56 0.00 0.00 4122 123260_99999 KRZESINY PL 52.332 16.966 20020601 20230103 60.11 18.59 59.95 4153 124030_99999 NOWE MIASTECZKO PL 51.683 15.733 19360102 19420630 60.70 0.00 0.00 4118 123120_99999 BABIMOST PL 52.139 15.799 20020603 20230103 61.96 18.58 59.94 4124 123300_99999 LAWICA PL 52.421 16.826 19310102 20230103 65.91 31.00 100.00 4163 124190_99999 JAROCIN PL 51.967 17.550 19391113 19420630 68.69 0.00 0.00 4150 124000_99999 ZIELONA GORA PL 51.933 15.533 19310101 20230103 71.99 31.00 100.00 4156 124060_99999 SZPROTAWA-WIECHLICE PL 51.561 15.585 19390815 20191108 75.30 29.85 96.30 9.3 Task 3 Identify suitable weather stations for patching gaps After reviewing the nearest weather stations to the Leszno location, KRZESINY, BABIMOST and LAWICA stations were identified as suitable for filling in the gaps in temperature data. These stations are ranked 4th, 6th and 7th on the list. All used locations have been plotted on the map. library(leaflet) df &lt;- data.frame(lat = c(52.332, 52.139, 52.421, 51.833), lng = c(16.966, 15.799, 16.826, 16.533), label = c(&quot;KRZESINY&quot;, &quot;BABIMOST&quot;, &quot;LAWICA&quot;, &quot;LESZNO&quot;)) m &lt;- leaflet(width = &quot;500px&quot;, height = &quot;300px&quot;) m &lt;- addTiles(m) m &lt;- addMarkers(m, data = df, label = ~label, lat = ~lat, lng = ~lng, labelOptions = labelOptions(direction = &quot;auto&quot;)) m 9.4 Task 4 Download weather data for promising stations, convert them to chillR format and compile them in a list Weather data from the previously selected stations must now be downloaded. To avoid having to do this every time, the data is saved using the save_temperature_scenario() function and subsequently loaded using the load_temperature_scenarios() function. Afterwards, some statistics are used to determine the success of the data completion. # create a vector for looping # positions_in_station_list&lt;-c(4,6,7) # create empty list # patch_weather&lt;-list() # for(i in 1:length(positions_in_station_list)) # { # patch_weather[[i]] &lt;- # handle_gsod( # handle_gsod( # action = &quot;download_weather&quot;, # location = station_list_close_to_leszno$chillR_code[positions_in_station_list[i]], # time_interval = c(1990, 2020) # ) # )[[1]]$weather # names(patch_weather)[i] &lt;- # station_list_close_to_leszno$STATION.NAME[positions_in_station_list[i]] # } # save result # save_temperature_scenarios(patch_weather,&quot;weather_data/gepatchtes_Wetter_PL&quot;, &quot;patch_weather_pl&quot;) #load result patch_weather&lt;-load_temperature_scenarios(&quot;weather_data/gepatchtes_Wetter_PL&quot;, &quot;patch_weather_pl&quot;) 9.5 Task 5 Use the patch_daily_temperatures function to fill gaps The patch_daily_temperatures() function can be used to fill in missing data in the records of the starting weather station, in this case Leszno. # Fill in the gaps in Leszno and save in a new variable patched patched&lt;-patch_daily_temperatures(weather = Leszno, patch_weather = patch_weather) Let’s first look at the statistics in Table 9.3 Patches statistics for KRZESNY. The table consists of two rows in total, Tmin and Tmax. The first column is called mean_bias. In Table 9.3, it shows -0.931 for Tmin and 0.730 for Tmax. These numbers represent the average difference in mean temperature for daily maximum and minimum temperature, respectively, between the stations Leszno and KRZESNY. All data that is available for both stations is compared. The filled column indicates how many days were filled with data from the auxiliary station. In this case, 5347 days were taken from the records of station KRZESNY and inserted into the dataset of station Leszno. The gaps_remain column shows how many gaps still exist. kable(patched$statistics[[1]], caption = paste(&quot;Patch statistics for&quot;, names(patched$statistics)[1])) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.3: Patch statistics for KRZESINY mean_bias stdev_bias filled gaps_remain Tmin -0.931 1.632 5347 1299 Tmax 0.730 1.365 5347 1299 kable(patched$statistics[[2]], caption = paste(&quot;Patch statistics for&quot;, names(patched$statistics)[2])) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.3: Patch statistics for BABIMOST mean_bias stdev_bias filled gaps_remain Tmin -1.114 2.14 334 965 Tmax 0.297 1.37 334 965 kable(patched$statistics[[3]], caption = paste(&quot;Patch statistics for&quot;, names(patched$statistics)[3])) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.3: Patch statistics for LAWICA mean_bias stdev_bias filled gaps_remain Tmin -0.415 1.533 963 2 Tmax 0.134 1.230 963 2 The patch_daily_temperatures() function allows the use of the arguments max_mean_bias and max_stdev_bias. These can be used to identify large temperature differences between the starting station and auxiliary station. For example, if these arguments are set to 1 °C for max_mean_bias and 2 °C max_stdev_bias, temperatures from the corresponding auxiliary station are only used if the deviation from max_mean_bias is less than or equal to 1 and from max_stdev_bias if the deviation is less than or equal to 2. # Fill in the gaps in Leszno and save in a new variable patched # set max_mean_bias = 1 and max_stdev_bias = 2 patched&lt;-patch_daily_temperatures(weather = Leszno, patch_weather = patch_weather, max_mean_bias = 1, max_stdev_bias = 2) If we look at Table 9.4 Patch statistics for BABIMOST, we can see that no Tmin temperatures were used to fill in the Leszno dataset. The mean_bias in this example is -1.114 and stdev_bias is 2.14. The amount of both values is therefore greater than 1 and 2. The filled column, as expected, shows that no data was used to fill in the starting weather station Leszno. kable(patched$statistics[[1]], caption = paste(&quot;Patch statistics for&quot;, names(patched$statistics)[1])) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.4: Patch statistics for KRZESINY mean_bias stdev_bias filled gaps_remain Tmin -0.931 1.632 5347 1299 Tmax 0.730 1.365 5347 1299 kable(patched$statistics[[2]], caption = paste(&quot;Patch statistics for&quot;, names(patched$statistics)[2])) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.4: Patch statistics for BABIMOST mean_bias stdev_bias filled gaps_remain Tmin -1.114 2.14 0 1299 Tmax 0.297 1.37 334 965 kable(patched$statistics[[3]], caption = paste(&quot;Patch statistics for&quot;, names(patched$statistics)[3])) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.4: Patch statistics for LAWICA mean_bias stdev_bias filled gaps_remain Tmin -0.388 1.517 1297 2 Tmax 0.134 1.230 963 2 Finally, the fix_weather() function can be used to check how well the temperature dataset can be completed post_patch_stats&lt;-fix_weather(patched)$QC kable(post_patch_stats, caption = &quot;Data completeness table for the weather record from Leszno, after applying the patch procedure&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) %&gt;% scroll_box(width = &quot;100%&quot;) Table 9.5: Data completeness table for the weather record from Leszno, after applying the patch procedure Season End_year Season_days Data_days Missing_Tmin Missing_Tmax Incomplete_days Perc_complete 1989/1990 1990 365 365 0 0 0 100.0 1990/1991 1991 365 365 0 0 0 100.0 1991/1992 1992 366 366 0 0 0 100.0 1992/1993 1993 365 365 0 0 0 100.0 1993/1994 1994 365 365 0 0 0 100.0 1994/1995 1995 365 365 0 0 0 100.0 1995/1996 1996 366 366 0 0 0 100.0 1996/1997 1997 365 365 0 0 0 100.0 1997/1998 1998 365 365 0 0 0 100.0 1998/1999 1999 365 365 1 1 1 99.7 1999/2000 2000 366 366 0 0 0 100.0 2000/2001 2001 365 365 0 0 0 100.0 2001/2002 2002 365 365 0 0 0 100.0 2002/2003 2003 365 365 0 0 0 100.0 2003/2004 2004 366 366 0 0 0 100.0 2004/2005 2005 365 365 0 0 0 100.0 2005/2006 2006 365 365 0 0 0 100.0 2006/2007 2007 365 365 0 0 0 100.0 2007/2008 2008 366 366 0 0 0 100.0 2008/2009 2009 365 365 0 0 0 100.0 2009/2010 2010 365 365 0 0 0 100.0 2010/2011 2011 365 365 0 0 0 100.0 2011/2012 2012 366 366 0 0 0 100.0 2012/2013 2013 365 365 0 0 0 100.0 2013/2014 2014 365 365 0 0 0 100.0 2014/2015 2015 365 365 0 0 0 100.0 2015/2016 2016 366 366 0 0 0 100.0 2016/2017 2017 365 365 0 0 0 100.0 2017/2018 2018 365 365 0 0 0 100.0 2018/2019 2019 365 365 0 0 0 100.0 2019/2020 2020 366 366 1 1 1 99.7 Leszno_weather_fix = fix_weather(patched) #write.csv(Leszno_weather_fix$weather,&quot;weather_data/Leszno_weather.csv&quot;) "],["generating-temperature-scenarios.html", "Chapter 10 Generating temperature scenarios 10.1 Task 1 10.2 Task 2 10.3 Task 3", " Chapter 10 Generating temperature scenarios 10.1 Task 1 For the location you chose for your earlier analyses, use chillR’s weather generator to produce 100 years of synthetic temperature data. A weather generator can be used to generate synthetic weather data. Chill R uses the generator from the RMAWGEN package. In order to generate weather data, the weather generator needs to be calibrated using original data. In this example, the weather data set for the Leszno location, generated in previous chapters, is used for calibration. Generating the weather data takes a little time. Therefore, as in previous chapters, the generated data is saved and then read in at this point. # load completed temperature #df_lz = read.csv(&quot;weather_data/Leszno_weather.csv&quot;, header = TRUE) # use handle_gsod for preparation #LZ_weather = handle_gsod(df_lz) # run the temperature generator #Temp&lt;-temperature_generation(LZ_weather, # years=c(1998,2005), # sim_years = c(2001,2100)) # plot measured values and simulated values # pull the data set from the list Temp #Temp = Temp[[1]] # why is there an additional column? -&gt; remove the col nodata from data set! #Temp = Temp[,-c(5)] # create dataframe Temperatures with the temperature information from 1998 - 2005 #Temperatures&lt;-cbind(LZ_weather[ # which(LZ_weather$Year %in% 1998:2005),] ,Data_source=&quot;observed&quot;) # cause of using the handle_gsod() function there are the # col´s prec and mean Temp which should deleted #Temperatures = Temperatures[,-c(7,8)] # create final data frame Temperatures #Temperatures&lt;-rbind(Temperatures, # cbind(Temp[,c(&quot;DATE&quot;,&quot;Year&quot;,&quot;Month&quot;,&quot;Day&quot;,&quot;Tmin&quot;,&quot;Tmax&quot;)], # Data_source=&quot;simulated&quot;)) #Temperatures[,&quot;Date&quot;]&lt;-as.Date(ISOdate(2000, # Temperatures$Month, # Temperatures$Day)) #write.csv(Temperatures, &quot;weather_data/Lezno_sim_temperatures.csv&quot;) Temperatur_s = read.table(&quot;weather_data/Lezno_sim_temperatures.csv&quot;, header = TRUE, sep = &quot;,&quot;) Temperatur_s$Date = as.Date(ISOdate(2000, Temperatur_s$Month, Temperatur_s$Day)) # Plot results ggplot(data = Temperatur_s, aes(Date, Tmin)) + geom_smooth(aes(colour = factor(Year))) + facet_wrap(vars(Data_source)) + theme_bw(base_size = 20) + theme(legend.position = &quot;none&quot;) + scale_x_date(date_labels = &quot;%b&quot;) ggplot(data = Temperatur_s, aes(Date, Tmax)) + geom_smooth(aes(colour = factor(Year))) + facet_wrap(vars(Data_source)) + theme_bw(base_size = 20) + theme(legend.position = &quot;none&quot;) + scale_x_date(date_labels = &quot;%b&quot;) 10.2 Task 2 Calculate winter chill (in Chill Portions) for your synthetic weather, and illustrate your results as histograms and cumulative distributions. # calculate chill for observed # chill_observed&lt;-chilling( # stack_hourly_temps( # Temperatur_s[which(Temperatur_s$Data_source==&quot;observed&quot;),], # latitude = 51.39), # change latitude # Start_JDay = 305, # End_JDay = 59) #write.csv(chill_observed, &quot;chill_observed.csv&quot;) chill_observed = read.csv(&quot;chill_observed.csv&quot;) # calculate chill for simulated # chill_simulated&lt;-chilling( # stack_hourly_temps( # Temperatur_s[which(Temperatur_s$Data_source==&quot;simulated&quot;),], # latitude = 51.39), # change latitude # Start_JDay = 305, # End_JDay = 59) #write.csv(chill_simulated, &quot;chill_simulated.csv&quot;) chill_simulated = read.csv(&quot;chill_simulated.csv&quot;) # build data frame chill_comparison&lt;-cbind(chill_observed ,Data_source=&quot;observed&quot;) chill_comparison&lt;-rbind(chill_comparison, cbind(chill_simulated ,Data_source=&quot;simulated&quot;)) chill_comparison_full_seasons&lt;-chill_comparison[ which(chill_comparison$Perc_complete==100),] # visualize ggplot(chill_comparison_full_seasons, aes(x=Chill_portions)) + geom_histogram(binwidth=1,aes(fill = factor(Data_source))) + theme_bw(base_size = 20) + labs(fill = &quot;Data source&quot;) + xlab(&quot;Chill accumulation (Chill Portions)&quot;) + ylab(&quot;Frequency&quot;) chill_simulations&lt;-chill_comparison_full_seasons[ which(chill_comparison_full_seasons$Data_source==&quot;simulated&quot;),] ggplot(chill_simulations, aes(x=Chill_portions)) + stat_ecdf(geom = &quot;step&quot;,lwd=1.5,col=&quot;blue&quot;) + ylab(&quot;Cumulative probability&quot;) + xlab(&quot;Chill accumulation (in Chill Portions)&quot;) + theme_bw(base_size = 20) 10.3 Task 3 Produce similar plots for the number of freezing hours (&lt;0°C) in April (or October, if your site is in the Southern Hemisphere) for your location of interest. # Observed frost hours Leszno_observed_hourly_temp = stack_hourly_temps(Temperatur_s[which (Temperatur_s$Data_source ==&quot;observed&quot;), ], latitude = 51.39) april_observes = Leszno_observed_hourly_temp[[1]] april_observes = april_observes[which(april_observes$Month == 4),] # data preparation april_observes = data.frame(Date = april_observes$DATE, case = april_observes$Data_source, Temp = april_observes$Temp) april_observes$date_new = as.POSIXct(april_observes$Date) # write function to count frost hours FH&lt;-function(hourtemps) { hourtemps[,&quot;frost_hours&quot;]&lt;-hourtemps$Temp&lt;0.00 return(hourtemps) } # apply FH function april_observes_frost = FH(april_observes) april_observes_frost$date_new_new = as.Date(april_observes_frost$date_new, format=&quot;%d.%m.%Y&quot;) #groupe april_observes_frost_cum = group_by(april_observes_frost, Year =year(date_new_new))%&gt;% summarise(Frost_hours_april =sum(frost_hours)) april_observes_frost_cum[,&quot;case&quot;] = rep(&quot;observed&quot;, length(april_observes_frost_cum$Year)) # Simulated Procedure Leszno_sim_hourly_temp = stack_hourly_temps(Temperatur_s[which (Temperatur_s$Data_source ==&quot;simulated&quot;), ], latitude = 51.39) april_sim = Leszno_sim_hourly_temp[[1]] april_sim = april_sim[which(april_sim$Month == 4),] april_sim = data.frame(Date = april_sim$DATE, case = april_sim$Data_source, Temp = april_sim$Temp) april_sim_frost = FH(april_sim) april_sim_frost$date_new = as.POSIXct(april_sim_frost$Date) april_sim_frost$date_new_new = as.Date(april_sim_frost$date_new, format=&quot;%d.%m.%Y&quot;) april_sim_frost_cum = group_by(april_sim_frost, Year =year(date_new_new))%&gt;% summarise(Frost_hours_april =sum(frost_hours)) april_sim_frost_cum[,&quot;case&quot;] = rep(&quot;simulated&quot;, length(april_sim_frost_cum$Year)) kable(head(april_observes_frost_cum), caption=&quot;Observed Frost Hours at Lezno in April 1998 to 2005&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 10.1: Observed Frost Hours at Lezno in April 1998 to 2005 Year Frost_hours_april case 1998 22 observed 1999 8 observed 2000 23 observed 2001 33 observed 2002 54 observed 2003 105 observed kable(head(april_sim_frost_cum), caption=&quot;Simulated Frost Hours at Lezno in April 2001 to 2100&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 10.1: Simulated Frost Hours at Lezno in April 2001 to 2100 Year Frost_hours_april case 2001 14 simulated 2002 107 simulated 2003 51 simulated 2004 46 simulated 2005 55 simulated 2006 24 simulated # create plot compairson = rbind(april_observes_frost_cum, april_sim_frost_cum) ggplot(compairson, aes(x=Frost_hours_april)) + geom_histogram(binwidth=1,aes(fill = factor(case))) + theme_bw(base_size = 20) + labs(fill = &quot;Data source&quot;) + xlab(&quot;Freezing Hours April Leszno &quot;) + ylab(&quot;Frequency&quot;) frost_simulations&lt;-compairson[ which(compairson$case==&quot;simulated&quot;),] ggplot(frost_simulations, aes(x=Frost_hours_april)) + stat_ecdf(geom = &quot;step&quot;,lwd=1.5,col=&quot;blue&quot;) + ylab(&quot;Cumulative probability&quot;) + xlab(&quot;Freezing Hours April Leszno Simulated&quot;) + theme_bw(base_size = 20) "],["historic-temperature-scenario.html", "Chapter 11 Historic Temperature Scenario 11.1 Task 1 11.2 Task 2", " Chapter 11 Historic Temperature Scenario 11.1 Task 1 For the location you chose for previous exercises, produce historic temperature scenarios representing several years of the historic record (your choice) A weather generator can generate weather scenarios that are based on previously inputted calibration weather data. For example, you can input weather records for a specific location into the generator for a period of 10 years and the generated scenarios will be strongly based on the calibration weather data. It is often desirable to represent the weather events of the past for a specific time period. How can this be implemented? If a scenario is to be created that represents the period from 1973 to 2019, the median could be chosen, in this case the year 1996, and a simulation could be carried out using the generator based on that. The consequence would be that you would get a representation of the weather events around the year 1996. However, this does not adequately reflect the change in climate from 1980 to 2010. It would be much more interesting to examine how the climate developed from 1980 to 2010. To do this, you could consider the years 1980, 1990, 2000, and 2010. Initially, weather data for the location Leszno is loaded, as previously described in the previous chapter. This time, the data covers the period from 1973 to 2019. # station_list = handle_gsod(action = &quot;list_stations&quot;, location = c(16.5, 51.39), # time_interval=c(1973,2019)) # write.csv(station_list, &quot;weather_data/Leszno_weather_raw/station_list_close_leszno_to_fill_gaps_raw.csv&quot;, # row.names = FALSE) # Leszno_weather_raw&lt;-handle_gsod(action=&quot;download_weather&quot;, # location=station_list$chillR_code[7], # time_interval = c(1973,2019), # station_list = station_list) #dir.create(&quot;weather_data/Leszno_weather_raw&quot;) #write.csv(Leszno_weather_raw,&quot;weather_data/Leszno_weather_raw/Leszno_weather_raw.csv&quot;,row.names=FALSE) Leszno_weather_raw = read.table(&quot;weather_data/Leszno_weather_raw/Leszno_weather_raw.csv&quot;, header = TRUE, sep = &quot;,&quot;) Leszno_weather_raw_station_list = read.table(&quot;weather_data/Leszno_weather_raw/station_list_close_leszno_to_fill_gaps_raw.csv&quot;, header = TRUE, sep = &quot;,&quot;) # Leszno_weather&lt;-handle_gsod(Leszno_weather_raw) # detect many gaps # fix_weather(Leszno_weather)$QC # positions_in_station_list&lt;-c(2,4,7,12,21) # patch_weather_l&lt;-list() # fill gaps for 1973 to 2019 # for(i in 1:length(positions_in_station_list)) # { # patch_weather_l[[i]] &lt;- # handle_gsod( # handle_gsod( # action = &quot;download_weather&quot;, # location = Leszno_weather_raw_station_list$chillR_code[positions_in_station_list[i]], # time_interval = c(1973, 2019) # ) # )[[1]]$weather # names(patch_weather_l)[i] &lt;- # Leszno_weather_raw_station_list$STATION.NAME[positions_in_station_list[i]] # } # patched_l&lt;-patch_daily_temperatures(weather = Leszno_weather, # patch_weather = patch_weather_l) #write.csv(fix_weather(patched_l)$QC,&quot;weather_data/Leszno_weather_raw/QC_Check.csv&quot;) QC = read.table(&quot;weather_data/Leszno_weather_raw/QC_Check.csv&quot;, header = TRUE, sep =&quot;,&quot;) kable(head(QC), caption=&quot;Filled gaps from 1973 to 2019 QC &quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 11.1: Filled gaps from 1973 to 2019 QC X Season End_year Season_days Data_days Missing_Tmin Missing_Tmax Incomplete_days Perc_complete 1 1972/1973 1973 365 365 2 2 2 99.5 2 1973/1974 1974 365 365 0 0 0 100.0 3 1974/1975 1975 365 365 1 1 1 99.7 4 1975/1976 1976 366 366 0 0 0 100.0 5 1976/1977 1977 365 365 0 0 0 100.0 6 1977/1978 1978 365 365 0 0 0 100.0 #Leszno_Sc&lt;-fix_weather(patched_l) #Leszno_Sc_temps&lt;-Leszno_Sc$weather #write.csv(Leszno_Sc_temps, &quot;weather_data/Leszno_weather_raw/Leszno_Sc_temps.csv&quot;) Leszno_Sc_temps = read.table(&quot;weather_data/Leszno_weather_raw/Leszno_Sc_temps.csv&quot;, header = TRUE, sep =&quot;,&quot;) kable(head(Leszno_Sc_temps), caption=&quot;Filled gaps from 1973 to 2019 &quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 11.1: Filled gaps from 1973 to 2019 X YEARMODA DATE Year Month Day Tmin Tmax Tmean Prec Tmin_source Tmax_source no_Tmin no_Tmax 1 19730101 1973-01-01 12:00:00 1973 1 1 -1.0000000 5.0000000 1.222222 0 NA NA FALSE FALSE 2 19730102 1973-01-02 12:00:00 1973 1 2 -5.2964918 2.5814462 NA NA daily_LEGNICA daily_LEGNICA FALSE FALSE 3 19730103 1973-01-03 12:00:00 1973 1 3 -8.2964918 -1.4185538 NA NA daily_LEGNICA daily_LEGNICA FALSE FALSE 4 19730104 1973-01-04 12:00:00 1973 1 4 -3.2964918 -0.6609859 NA NA daily_LEGNICA daily_STRACHOWICE FALSE FALSE 5 19730105 1973-01-05 12:00:00 1973 1 5 -1.2964918 -0.4185538 NA NA daily_LEGNICA daily_LEGNICA FALSE FALSE 6 19730106 1973-01-06 12:00:00 1973 1 6 -0.2964918 1.5814462 NA NA daily_LEGNICA daily_LEGNICA FALSE FALSE Firstly, a realistic temperature scenario for 1980 must be created, based on actual observed data. This can be done using the function temperature_scenario_from_record(). The previously loaded and complemented weather data is passed to the argument weather, and the argument year is set to 1980. scenario_1980 = temperature_scenario_from_records(weather=Leszno_Sc_temps,year=1980) kable(scenario_1980$&#39;1980&#39;$data, caption = &quot;Temperature Scenario 1980&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;,font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 11.2: Temperature Scenario 1980 Tmin Tmax -4.3191108 0.7088587 -4.2522096 1.6761109 0.0017841 7.5296426 2.4312213 11.9301075 7.5154979 17.9306386 10.5285472 20.8788868 12.0419278 22.1888514 11.8209322 22.4400381 8.7624918 18.5001354 4.9667784 12.8319967 0.9569230 6.6452393 -1.8776562 2.8248863 We obtain a temperature scenario containing mean monthly high and low values. This is based on the observed data that was actually measured in 1980. Table ‘Temperature Scenario 1980’ shows this. Since we also want to consider the years 1990, 2000, and 2010, we include them as well. all_past_scenarios = temperature_scenario_from_records(weather = Leszno_Sc_temps, year = c(1980, 1990, 2000, 2010)) If the weather generator were to be run based on these temperature scenarios (1980, 1990, 2000, 2010), it would produce absolute temperature scenarios. However, as mentioned earlier, it is much more interesting to compare how the climate has changed relatively over time. For this purpose, a year can be used as a baseline. In this case, 1996 is chosen as it represents the median of the time interval. The function temperature_scenario_baseline_adjustment() can be used to create a relative temperature scenario that can later be passed to the function temperature_generation(). However, first the year 1996 must be generated: scenario_1996 = temperature_scenario_from_records(weather=Leszno_Sc_temps,year=1996) After this has been done, the relative scenarios can be created. To do this, the function temperature_scenario_baseline_adjustment() is passed the previously generated scenario for the year 1996 to the arguments baseline and temperature_scenario, and the variable all_past_scenarios, in which the scenarios for 1980, 1990, 2000, and 2010 are stored. adjusted_scenarios= temperature_scenario_baseline_adjustment( baseline=scenario_1996, temperature_scenario = all_past_scenarios) Now we can pass all of the information to the function temperature_generation(). # all_past_scenario_temps&lt;-temperature_generation( # weather=Leszno_Sc_temps, # years=c(1973,2019), # sim_years=c(2001,2100), # temperature_scenario = adjusted_scenarios) This takes a lot of time, so the scenarios are saved using the function save_temperature_scenarios() and immediately reloaded using the function load_temperature_scenarios(). # save_temperature_scenarios(all_past_scenario_temps, &quot;All_Scenarios_Leszno&quot;,&quot;all_past_scenario_temps&quot;) all_past_scenario_temps= load_temperature_scenarios(&quot;All_Scenarios_Leszno&quot;,&quot;all_past_scenario_temps&quot;) The function tempResponse_daily_list() can now be used to calculate the historic chill. # chill_hist_scenario_list = # tempResponse_daily_list(all_past_scenario_temps, # latitude=51.39, # Start_JDay = 305, # End_JDay = 59) # save_temperature_scenarios(chill_hist_scenario_list, &quot;chill_hist_scenario_list&quot;,&quot;chill_hist_scenario_list&quot;) chill_hist_scenario_list= load_temperature_scenarios(&quot;chill_hist_scenario_list&quot;,&quot;chill_hist_scenario_list&quot;) 11.2 Task 2 Produce chill distributions for these scenarios and plot them. Now the chill and temperature development over the years can be plotted graphically. scenarios&lt;-names(chill_hist_scenario_list)[1:4] all_scenarios&lt;-chill_hist_scenario_list[[scenarios[1]]] all_scenarios[,&quot;scenario&quot;]&lt;-as.numeric(scenarios[1]) for (sc in scenarios[2:4]) all_scenarios = rbind(all_scenarios, cbind(chill_hist_scenario_list[[sc]],scenario=as.numeric(sc))) all_scenarios&lt;-all_scenarios[which(all_scenarios$Perc_complete==100),] actual_chill&lt;-tempResponse_daily_list(Leszno_Sc_temps,latitude=50.9, Start_JDay = 305, End_JDay = 59)[[1]] actual_chill&lt;-actual_chill[which(actual_chill$Perc_complete==100),] ggplot(data=all_scenarios,aes(scenario,Chill_Portions, fill=factor(scenario))) + geom_violin() + ylab(&quot;Chill accumulation (Chill Portions)&quot;) + xlab(&quot;Scenario year&quot;) + theme_bw(base_size=15) + ylim(c(0,90)) + geom_point(data=actual_chill, aes(End_year,Chill_Portions,fill=&quot;blue&quot;), col=&quot;blue&quot;,show.legend = FALSE) + scale_fill_discrete(name=&quot;Scenario&quot;, breaks = unique(all_scenarios$scenario)) The results regarding the expected chill hours can be very well represented in a violin plot. Each year on the X axis (1980,1990,2000,2010) contains 100 years of simulations of chill hours. The relative reference to the year 1996 is considered. This explains the slight increase in chill hours. The reason for this is that at temperatures below zero degrees generally less chill hours occur. Since it was colder in 1980, less chill hours can be expected on the climate basis of that time than in 1990 or 2000 or 2010. At the end plots are created which represent the Tmin Temperature and Tmax Temperature. temperature_means = data.frame(Year=min(Leszno_Sc_temps$Year):max(Leszno_Sc_temps$Year), Tmin=aggregate(Leszno_Sc_temps$Tmin,FUN=&quot;mean&quot;, by=list(Leszno_Sc_temps$Year))[,2], Tmax=aggregate(Leszno_Sc_temps$Tmax,FUN=&quot;mean&quot;, by=list(Leszno_Sc_temps$Year))[,2]) temperature_means[,&quot;runn_mean_Tmin&quot;] = runn_mean(temperature_means$Tmin,15) temperature_means[,&quot;runn_mean_Tmax&quot;] = runn_mean(temperature_means$Tmax,15) Tmin_regression = lm(Tmin~Year, temperature_means) temperature_means[,&quot;regression_Tmin&quot;] = Tmin_regression$coefficients[1]+ Tmin_regression$coefficients[2]*temperature_means$Year Tmax_regression = lm(Tmax~Year, temperature_means) temperature_means[,&quot;regression_Tmax&quot;] = Tmax_regression$coefficients[1]+ Tmax_regression$coefficients[2]*temperature_means$Year ggplot(temperature_means,aes(Year, Tmin)) + geom_point() + geom_line(data=temperature_means,aes(Year, runn_mean_Tmin),lwd=2,col=&quot;blue&quot;) + geom_line(data=temperature_means,aes(Year, regression_Tmin),lwd=2,col=&quot;red&quot;) + theme_bw(base_size=15) + ylab(&quot;Mean monthly minimum temperature (°C)&quot;) ggplot(temperature_means,aes(Year, Tmax)) + geom_point() + geom_line(data=temperature_means,aes(Year, runn_mean_Tmax),lwd=2,col=&quot;blue&quot;) + geom_line(data=temperature_means,aes(Year, regression_Tmax),lwd=2,col=&quot;red&quot;) + theme_bw(base_size=15) + ylab(&quot;Mean monthly maximum temperature (°C)&quot;) "],["future-temperature-scenarios.html", "Chapter 12 Future Temperature Scenarios 12.1 Task 1", " Chapter 12 Future Temperature Scenarios 12.1 Task 1 Analyze the historic and future impact of climate change on three agroclimatic metrics of your choice, for the location you’ve chosen for your earlier analyses. Up until now, historical temperature scenarios have been created based on different years. Currently, there are many models that provide future climate data. Here, the ClimateWizard model developed by Dr. Evan Girvetz is used. This model can be accessed through an API, allowing for corresponding climate data to be downloaded. Currently, there is no function for simultaneously loading multiple RCPs. Therefore, a for loop is used in this case. It should also be noted that the ClimateWizard requires a data base over a 20 year period between 1950 and 2005. Therefore, our previously generated data must be adjusted. Here, the period from 1975 to 2005, contained in the complementary data set from Leszno, is chosen. Afterwards, the climate scenario is saved. #dir.create(&quot;weather_data/Leszno_weather_raw/ClimateWizard_Leszno&quot;) # RCPs&lt;-c(&quot;rcp45&quot;,&quot;rcp85&quot;) # Times&lt;-c(2050,2085) # for(RCP in RCPs) # for (Time in Times) # { # start_year &lt;- Time - 15 # end_year &lt;- Time + 15 # clim_scen &lt;- getClimateWizardData( # c(longitude = 16.580, latitude = 51.851), # RCP, # start_year, # end_year, # temperature_generation_scenarios = TRUE, # baseline = c(1975, 2005), # metric = &quot;monthly_min_max_temps&quot;, # GCMs = &quot;all&quot; # ) # save_temperature_scenarios(clim_scen, # &quot;weather_data/Leszno_weather_raw/ClimateWizard_Leszno&quot;, # paste0(&quot;Leszno_futures_&quot;, Time, &quot;_&quot;, RCP)) # } scenario_1990 = temperature_scenario_from_records(Leszno_Sc_temps,1990) scenario_1996 = temperature_scenario_from_records(Leszno_Sc_temps,1996) adjustment_scenario = temperature_scenario_baseline_adjustment(scenario_1996,scenario_1990) #dir.create(&quot;weather_data/Leszno_weather_raw/Leszno_&quot;) RCPs&lt;-c(&quot;rcp45&quot;,&quot;rcp85&quot;) Times&lt;-c(2050,2085) # # for(RCP in RCPs) # for(Time in Times) # { # clim_scen&lt;-load_ClimateWizard_scenarios( # &quot;weather_data/Leszno_weather_raw/ClimateWizard_Leszno&quot;, # paste0(&quot;Leszno_futures_&quot;,Time,&quot;_&quot;,RCP)) # clim_scen_adjusted&lt;- # temperature_scenario_baseline_adjustment( # baseline_temperature_scenario=adjustment_scenario, # temperature_scenario=clim_scen) # Temps&lt;-temperature_generation( # weather=Leszno_Sc_temps, # years=c(1973,2019), # sim_years=c(2001,2101), # temperature_scenario = clim_scen_adjusted) # # save_temperature_scenarios( # Temps, # &quot;weather_data/Leszno_weather_raw/Leszno_&quot;, # paste0(&quot;Leszno_&quot;,Time,&quot;_&quot;,RCP)) # } all_past_scenarios = temperature_scenario_from_records( weather=Leszno_Sc_temps, year=c(1980,1990,2000,2010)) adjusted_scenarios = temperature_scenario_baseline_adjustment( baseline=scenario_1996, temperature_scenario = all_past_scenarios) # all_past_scenario_temps&lt;-temperature_generation( # weather=Leszno_Sc_temps, # years=c(1973,2019), # sim_years=c(2001,2101), # temperature_scenario = adjusted_scenarios) # save_temperature_scenarios( # all_past_scenario_temps, # &quot;weather_data/Leszno_weather_raw&quot;, # &quot;Leszno_historic&quot;) frost_model = function(x) step_model(x,data.frame( lower=c(-1000,0), upper=c(0,1000), weight=c(1,0))) models = list(Chill_CP=Dynamic_Model,Heat_GDH=GDH,Frost_H=frost_model) Temps= load_temperature_scenarios(&quot;weather_data/Leszno_weather_raw&quot;,&quot;Leszno_historic&quot;) # chill_past_scenarios = tempResponse_daily_list( # Temps, # latitude=51.39, # Start_JDay = 305, # End_JDay = 59, # models=models, # misstolerance = 10) # chill_observed&lt;-tempResponse_daily_list( # Leszno_Sc_temps, # latitude=51.39, # Start_JDay = 305, # End_JDay = 59, # models=models, # misstolerance = 10) # save_temperature_scenarios(chill_past_scenarios, # &quot;weather_data/Leszno_weather_raw/chill&quot;, # &quot;Leszno_historic&quot;) # save_temperature_scenarios(chill_observed, # &quot;weather_data/Leszno_weather_raw/chill&quot;, # &quot;Leszno_observed&quot;) chill_past_scenarios = load_temperature_scenarios( &quot;weather_data/Leszno_weather_raw/chill&quot;, &quot;Leszno_historic&quot;) chill_observed = load_temperature_scenarios( &quot;weather_data/Leszno_weather_raw/chill&quot;, &quot;Leszno_observed&quot;) chills = make_climate_scenario( chill_past_scenarios, caption = &quot;Historic&quot;, historic_data = chill_observed, time_series = TRUE) plot_climate_scenarios( climate_scenario_list=chills, metric=&quot;Chill_CP&quot;, metric_label=&quot;Chill (Chill Portions)&quot;) ## [[1]] ## [1] &quot;time series labels&quot; # for(RCP in RCPs) # for(Time in Times) # { # Temps&lt;-load_temperature_scenarios( # &quot;weather_data/Leszno_weather_raw/Leszno_&quot;, # paste0(&quot;Leszno_&quot;,Time,&quot;_&quot;,RCP)) # chill&lt;-tempResponse_daily_list( # Temps, # latitude=51.39, # Start_JDay = 305, # End_JDay = 59, # models=models, # misstolerance = 10) # save_temperature_scenarios( # chill, # &quot;weather_data/Leszno_weather_raw/chill&quot;, # paste0(&quot;Leszno_&quot;,Time,&quot;_&quot;,RCP)) # } for(RCP in RCPs) for(Time in Times) { chill&lt;-load_temperature_scenarios( &quot;weather_data/Leszno_weather_raw/chill&quot;, paste0(&quot;Leszno_&quot;,Time,&quot;_&quot;,RCP)) if(RCP==&quot;rcp45&quot;) RCPcaption &lt;- &quot;RCP4.5&quot; if(RCP==&quot;rcp85&quot;) RCPcaption &lt;- &quot;RCP8.5&quot; if(Time==&quot;2050&quot;) Time_caption &lt;- &quot;2050&quot; if(Time==&quot;2085&quot;) Time_caption &lt;- &quot;2085&quot; chills &lt;-make_climate_scenario( chill, caption =c(RCPcaption, Time_caption), add_to = chills) } alpha = plot_climate_scenarios( climate_scenario_list=chills, metric=&quot;Chill_CP&quot;, metric_label=&quot;Chill (Chill Portions)&quot;, texcex=1.5) beat = plot_climate_scenarios( climate_scenario_list=chills, metric=&quot;Heat_GDH&quot;, metric_label=&quot;Heat (Growing Degree Hours)&quot;, texcex=1.5) gamma = plot_climate_scenarios( climate_scenario_list=chills, metric=&quot;Frost_H&quot;, metric_label=&quot;Frost hours&quot;, texcex=1.5) "],["plotting-future-scenarios.html", "Chapter 13 Plotting Future Scenarios 13.1 Task 1", " Chapter 13 Plotting Future Scenarios 13.1 Task 1 Produce similar plots for the weather station you selected for earlier exercises. In order to plot the results of the future scenarios, the ggpmisc and patchwork packages must first be loaded. library(patchwork) library(ggpmisc) In the following, the data about possible future scenarios are visualized with ggplot. for(nam in names(chills[[1]]$data)) { # Extract the data frame. ch&lt;-chills[[1]]$data[[nam]] # Add columns for the new information we have to add and fill them. ch[,&quot;GCM&quot;]&lt;-&quot;none&quot; ch[,&quot;RCP&quot;]&lt;-&quot;none&quot; ch[,&quot;Year&quot;]&lt;-as.numeric(nam) # Now check if this is the first time we&#39;ve gone through this loop. # If this is the first time, the ch data.frame becomes the output # object (past_simulated). # If it is not the first time (&#39;else&#39;), we add the current data.frame # to the &#39;past_simulated&#39; object if(nam==names(chills[[1]]$data)[1]) past_simulated&lt;-ch else past_simulated&lt;-rbind(past_simulated,ch) } past_simulated[&quot;Scenario&quot;] = &quot;Historic&quot; kable(past_simulated[1:5,]) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;,font_size = 8)%&gt;% scroll_box(width = &quot;100%&quot;) Season End_year Season_days Data_days Perc_complete Chill_CP Heat_GDH Frost_H GCM RCP Year Scenario 2001/2002 2002 120 120 100 68.02902 1626.6736 1162 none none 1980 Historic 2002/2003 2003 120 120 100 61.99433 380.7299 1567 none none 1980 Historic 2003/2004 2004 120 120 100 73.56170 576.6271 1228 none none 1980 Historic 2004/2005 2005 121 121 100 77.40701 1710.6912 1038 none none 1980 Historic 2005/2006 2006 120 120 100 69.60777 1054.0242 1216 none none 1980 Historic past_observed = chills[[1]][[&quot;historic_data&quot;]] kable(past_observed[1:5,]) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;,font_size = 8)%&gt;% scroll_box(width = &quot;100%&quot;) Season End_year Season_days Data_days Interpolated_days Perc_complete Chill_CP Heat_GDH Frost_H 1973/1974 1974 120 120 0 100 76.41768 1027.0165 880 1974/1975 1975 120 120 0 100 83.11956 897.6264 621 1975/1976 1976 120 120 0 100 66.97020 352.8386 1371 1976/1977 1977 121 121 0 100 65.59721 1041.0580 1285 1977/1978 1978 120 120 0 100 63.29490 1518.9264 1387 # Extract future data for(i in 2:length(chills)) for(nam in names(chills[[i]]$data)) {ch&lt;-chills[[i]]$data[[nam]] ch[,&quot;GCM&quot;]&lt;-nam ch[,&quot;RCP&quot;]&lt;-chills[[i]]$caption[1] ch[,&quot;Year&quot;]&lt;-chills[[i]]$caption[2] if(i==2&amp;nam==names(chills[[i]]$data)[1]) future_data&lt;-ch else future_data&lt;-rbind(future_data,ch) } kable(future_data[1:5,]) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;,font_size = 8)%&gt;% scroll_box(width = &quot;100%&quot;) Season End_year Season_days Data_days Perc_complete Chill_CP Heat_GDH Frost_H GCM RCP Year 2001/2002 2002 120 120 100 77.42519 2510.7338 896 bcc-csm1-1 RCP4.5 2050 2002/2003 2003 120 120 100 71.61278 853.1862 1256 bcc-csm1-1 RCP4.5 2050 2003/2004 2004 120 120 100 80.48400 1194.5720 775 bcc-csm1-1 RCP4.5 2050 2004/2005 2005 121 121 100 83.08626 3197.2233 695 bcc-csm1-1 RCP4.5 2050 2005/2006 2006 120 120 100 77.74917 2007.3718 891 bcc-csm1-1 RCP4.5 2050 # Extract the model names #Models = unique(future_data$GCM) metric = &quot;Heat_GDH&quot; axis_label = &quot;Heat (in GDH)&quot; # get extreme values for the axis scale rng = range(past_observed[[metric]], past_simulated[[metric]], future_data[[metric]]) past_plot= ggplot() + geom_boxplot(data = past_simulated, aes_string(&quot;as.numeric(Year)&quot;,metric,group=&quot;Year&quot;), fill=&quot;skyblue&quot;) past_plot = past_plot + scale_y_continuous(limits = c(0, round(rng[2] + rng[2]/10))) + labs(x = &quot;Year&quot;, y = axis_label) past_plot = past_plot + facet_grid(~ Scenario) + theme_bw(base_size = 15) past_plot = past_plot + theme(strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;), axis.text.x = element_text(angle=45, hjust=1)) past_plot = past_plot + geom_point(data = past_observed, aes_string(&quot;End_year&quot;,metric), col=&quot;blue&quot;) y = 2050 future_2050 = ggplot(data= future_data[which(future_data$Year==y),]) + geom_boxplot(aes_string(&quot;GCM&quot;, metric, fill=&quot;GCM&quot;)) future_2050 = future_2050 + facet_wrap(vars(RCP)) + scale_x_discrete(labels = NULL, expand = expansion(add = 1)) future_2050 = future_2050 + scale_y_continuous(limits = c(0, round(round(1.1*rng[2])))) + geom_text_npc(aes(npcx = &quot;center&quot;, npcy = &quot;top&quot;, label = Year), size = 5) future_2050 = future_2050 + theme_bw(base_size = 15) + theme(axis.ticks.y = element_blank(), axis.text = element_blank(), axis.title = element_blank(), legend.position = &quot;bottom&quot;, legend.margin = margin(0, 0, 0, 0, &quot;cm&quot;), legend.background = element_rect(), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;), legend.box.spacing = unit(0, &quot;cm&quot;), plot.subtitle = element_text(hjust = 0.5, vjust = -1, size = 15 * 1.05, face = &quot;bold&quot;)) future_plot_list&lt;-list() for(y in c(2050,2085)) { future_plot_list[[which(y == c(2050,2085))]] &lt;- ggplot(data= future_data[which(future_data$Year==y),]) + geom_boxplot(aes_string(&quot;GCM&quot;, metric, fill=&quot;GCM&quot;)) + facet_wrap(vars(RCP)) + scale_x_discrete(labels = NULL, expand = expansion(add = 1)) + scale_y_continuous(limits = c(0, round(round(1.1*rng[2])))) + geom_text_npc(aes(npcx = &quot;center&quot;, npcy = &quot;top&quot;, label = Year), size = 5) + theme_bw(base_size = 15) + theme(axis.ticks.y = element_blank(), axis.text = element_blank(), axis.title = element_blank(), legend.position = &quot;bottom&quot;, legend.margin = margin(0, 0, 0, 0, &quot;cm&quot;), legend.background = element_rect(), strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;), legend.box.spacing = unit(0, &quot;cm&quot;), plot.subtitle = element_text( hjust = 0.5, vjust = -1, size = 15 * 1.05, face = &quot;bold&quot;)) } both_plots = past_plot + future_plot_list plot = both_plots + plot_layout(guides = &quot;collect&quot;, widths = c(1,rep(1.8,length(future_plot_list)))) plot = plot &amp; theme(legend.position = &quot;bottom&quot;, legend.text = element_text(size=8), legend.title = element_text(size=10), axis.title.x=element_blank()) plt = plot + plot_annotation(title = &quot;Heat in GDH - Leszno PL&quot;, theme = theme(plot.title = element_text(size = 16))) plt #dir.create(&quot;Results&quot;) #ggsave(&quot;Result/GDH_Leszno.png&quot;, width = 30, height = 20, units = &quot;cm&quot;, dpi = 600) "],["chill-model-comparison.html", "Chapter 14 Chill Model Comparison 14.1 Task 1 14.2 Task 2 14.3 Task 3", " Chapter 14 Chill Model Comparison 14.1 Task 1 Perform a similar analysis for the location you’ve chosen for your exercises. First, it should be clarified what the so-called Safe Winter Chill is. Essentially, it is the chill that can be expected with certainty in 90% of cases. In other words, in nine out of ten years, at least this amount of chill will be reached. The data generated previously also contains information about the expected chill and can be well reduced to it. Different metrics are available for this. These models are compiled in the R package dormancyR and can be retrieved via GitHub. Initially, some installations need to be performed. Lets do this now! library(chillR) library(devtools) #install_github(&quot;EduardoFernandezC/dormancyR&quot;) # if it&#39;s installed, you don&#39;t need it again! library(dormancyR) library(tidyverse) library(reshape2) library(colorRamps) library(kableExtra) library(patchwork) library(gganimate) Now we can load all models and metrics. RCPs = c(&quot;rcp45&quot;,&quot;rcp85&quot;) # important for later Times = c(2050,2085) # important for later hourly_models = list( Chilling_units = chilling_units, Low_chill = low_chill_model, Modified_Utah = modified_utah_model, North_Carolina = north_carolina_model, Positive_Utah = positive_utah_model, Chilling_Hours = Chilling_Hours, Utah_Chill_Units = Utah_Model, Chill_Portions = Dynamic_Model ) daily_models = list( Rate_of_Chill = rate_of_chill, Chill_Days = chill_days, Exponential_Chill = exponential_chill, Triangula_Chill_Haninnen = triangular_chill_1, Triangular_Chill_Legave = triangular_chill_2 ) # gibt die Namen der beiden Listen zurück -&gt; &quot;hourly_models&quot; und &quot;daily_models&quot; metrics&lt;-c(names(daily_models),names(hourly_models)) model_labels=c(&quot;Rate of Chill&quot;, &quot;Chill Days&quot;, &quot;Exponential Chill&quot;, &quot;Triangular Chill (Häninnen)&quot;, &quot;Triangular Chill (Legave)&quot;, &quot;Chilling Units&quot;, &quot;Low-Chill Chill Units&quot;, &quot;Modified Utah Chill Units&quot;, &quot;North Carolina Chill Units&quot;, &quot;Positive Utah Chill Units&quot;, &quot;Chilling Hours&quot;, &quot;Utah Chill Units&quot;, &quot;Chill Portions&quot;) kable(data.frame(Metric=model_labels,&#39;Function name&#39;=metrics), caption = &quot;Metrics and Models&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;,font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 14.1: Metrics and Models Metric Function.name Rate of Chill Rate_of_Chill Chill Days Chill_Days Exponential Chill Exponential_Chill Triangular Chill (Häninnen) Triangula_Chill_Haninnen Triangular Chill (Legave) Triangular_Chill_Legave Chilling Units Chilling_units Low-Chill Chill Units Low_chill Modified Utah Chill Units Modified_Utah North Carolina Chill Units North_Carolina Positive Utah Chill Units Positive_Utah Chilling Hours Chilling_Hours Utah Chill Units Utah_Chill_Units Chill Portions Chill_Portions Now all chill models should be applied to the future temperature scenarios in Leszno. The temperature data can be easily loaded for this. Leszno_temps&lt;-read_tab(&quot;weather_data/Leszno_weather_raw/Leszno_Sc_temps.csv&quot;) Temps&lt;-load_temperature_scenarios(&quot;weather_data/Leszno_weather_raw&quot;,&quot;Leszno_historic&quot;) After the temperature data has been loaded and stored in the variables Leszno_temps and Temps, the various chill models can be applied to this data. Start_JDay = 305 End_JDay = 59 daily_models_past_scenarios = tempResponse_list_daily(Temps, Start_JDay = Start_JDay, End_JDay = End_JDay, models = daily_models) daily_models_past_scenarios = lapply(daily_models_past_scenarios, function(x) x[which(x$Perc_complete &gt; 90), ]) # hourly_models_past_scenarios = # tempResponse_daily_list( # Temps, # latitude = 51.39, # Start_JDay = Start_JDay, # End_JDay = End_JDay, # models = hourly_models, # misstolerance = 10 # ) #save_temperature_scenarios(hourly_models_past_scenarios,&quot;dormancyR&quot;,&quot;hourly_models_past_scenarios&quot;) hourly_models_past_scenarios = load_temperature_scenarios(&quot;dormancyR&quot;,&quot;hourly_models_past_scenarios&quot;) past_scenarios = daily_models_past_scenarios past_scenarios = lapply(names(past_scenarios), function(x) cbind(past_scenarios[[x]], hourly_models_past_scenarios[[x]][, names(hourly_models)])) names(past_scenarios) = names(daily_models_past_scenarios) daily_models_observed = tempResponse_daily( Leszno_temps, Start_JDay = Start_JDay, End_JDay = End_JDay, models = daily_models ) daily_models_observed = daily_models_observed[which(daily_models_observed$Perc_complete &gt; 90), ] # hourly_models_observed = # tempResponse_daily_list( # Leszno_temps, # latitude = 51.39, # Start_JDay = Start_JDay, # End_JDay = End_JDay, # models = hourly_models, # misstolerance = 10 # ) #save_temperature_scenarios(hourly_models_observed,&quot;dormancyR_hourly_models&quot;,&quot;hourly_models_observed&quot;) hourly_models_observed = load_temperature_scenarios(&quot;dormancyR_hourly_models&quot;,&quot;hourly_models_observed&quot;) # past_observed = # cbind(daily_models_observed, # hourly_models_observed[[1]][, names(hourly_models)]) # save_temperature_scenarios(past_scenarios, # &quot;weather_data/Leszno_weather_raw/chill&quot;, # &quot;Leszno_multichill_historic&quot;) # write.csv(past_observed, # &quot;weather_data/Leszno_weather_raw/chill/Leszno_multichill_observed.csv&quot;, # row.names=FALSE) past_observed = read.csv(&quot;weather_data/Leszno_weather_raw/chill/Leszno_multichill_observed.csv&quot;) RCPs&lt;-c(&quot;rcp45&quot;,&quot;rcp85&quot;) Times&lt;-c(2050,2085) # for(RCP in RCPs) # for(Time in Times) # { # Temps&lt;-load_temperature_scenarios( # &quot;weather_data/Leszno_weather_raw/Leszno_/&quot;, # paste0(&quot;Leszno_&quot;,Time,&quot;_&quot;,RCP)) # # daily_models_future_scenarios&lt;-tempResponse_list_daily( # Temps, # Start_JDay = Start_JDay, # End_JDay = End_JDay, # models=daily_models) # daily_models_future_scenarios&lt;-lapply( # daily_models_future_scenarios, # function(x) x[which(x$Perc_complete&gt;90),]) # hourly_models_future_scenarios&lt;- # tempResponse_daily_list( # Temps, # latitude=51.39, # Start_JDay = Start_JDay, # End_JDay = End_JDay, # models=hourly_models, # misstolerance = 10) # # future_scenarios&lt;-daily_models_future_scenarios # future_scenarios&lt;-lapply( # names(future_scenarios), # function(x) # cbind(future_scenarios[[x]], # hourly_models_future_scenarios[[x]][,names(hourly_models)])) # names(future_scenarios)&lt;-names(daily_models_future_scenarios) # # chill&lt;-future_scenarios # save_temperature_scenarios( # chill, # &quot;weather_data/Leszno_weather_raw/chill&quot;, # paste0(&quot;Leszno_multichill_&quot;,Time,&quot;_&quot;,RCP)) # } chill_past_scenarios = load_temperature_scenarios( &quot;weather_data/Leszno_weather_raw/chill&quot;, &quot;Leszno_multichill_historic&quot;) chill_observed = read_tab(&quot;weather_data/Leszno_weather_raw/chill/Leszno_multichill_observed.csv&quot;) chills = make_climate_scenario(chill_past_scenarios, caption = &quot;Historic&quot;, historic_data = chill_observed, time_series = TRUE) for(RCP in RCPs) for(Time in Times) { chill&lt;-load_temperature_scenarios( &quot;weather_data/Leszno_weather_raw/chill/&quot;, paste0(&quot;Leszno_multichill_&quot;,Time,&quot;_&quot;,RCP)) if(RCP==&quot;rcp45&quot;) RCPcaption &lt;- &quot;RCP4.5&quot; if(RCP==&quot;rcp85&quot;) RCPcaption &lt;- &quot;RCP8.5&quot; if(Time==&quot;2050&quot;) Time_caption &lt;- &quot;2050&quot; if(Time==&quot;2085&quot;) Time_caption &lt;- &quot;2085&quot; chills &lt;-make_climate_scenario(chill, caption =c(RCPcaption,Time_caption), add_to = chills) } for(i in 1:length(chills)) {ch&lt;-chills[[i]] if(ch$caption[1]==&quot;Historic&quot;) {GCMs&lt;-rep(&quot;none&quot;,length(names(ch$data))) RCPs&lt;-rep(&quot;none&quot;,length(names(ch$data))) Years&lt;-as.numeric(ch$labels) Scenario&lt;-rep(&quot;Historic&quot;,length(names(ch$data)))} else {GCMs&lt;-names(ch$data) RCPs&lt;-rep(ch$caption[1],length(names(ch$data))) Years&lt;-rep(as.numeric(ch$caption[2]),length(names(ch$data))) Scenario&lt;-rep(&quot;Future&quot;,length(names(ch$data)))} for(nam in names(ch$data)) {for(met in metrics) {temp_res&lt;-data.frame(Metric=met, GCM=GCMs[which(nam==names(ch$data))], RCP=RCPs[which(nam==names(ch$data))], Year=Years[which(nam==names(ch$data))], Result=quantile(ch$data[[nam]][,met],0.1), Scenario=Scenario[which(nam==names(ch$data))]) if(i==1&amp;nam==names(ch$data)[1]&amp;met==metrics[1]) results&lt;-temp_res else results&lt;-rbind(results,temp_res) }}} for(met in metrics) results[which(results$Metric==met),&quot;SWC&quot;]&lt;- results[which(results$Metric==met),&quot;Result&quot;]/ results[which(results$Metric==met&amp;results$Year==1980),&quot;Result&quot;]-1 rng = range(results$SWC) 14.2 Task 2 Make a heat map illustrating past and future changes in Safe Winter Chill, relative to a past scenario, for the 13 chill models used here p_future = ggplot(results[which(!results$GCM==&quot;none&quot;),], aes(GCM, y=factor(Metric, levels=metrics), fill = SWC)) + geom_tile()+ facet_grid(RCP ~ Year)+ theme_bw(base_size = 15) + theme(axis.text = element_text(size=8))+ scale_fill_gradientn(colours=matlab.like(15), labels = scales::percent, limits=rng)+ theme(axis.text.x = element_text(angle = 75, hjust = 1, vjust = 1)) + labs(fill = &quot;Change in\\nSafe Winter Chill\\nsince 1975&quot;) + scale_y_discrete(labels=model_labels) + ylab(&quot;Chill metric&quot;) p_future p_past = ggplot(results[which(results$GCM==&quot;none&quot;),], aes(Year, y=factor(Metric, levels=metrics), fill = SWC)) + geom_tile()+ theme_bw(base_size = 15) + theme(axis.text = element_text(size=8))+ scale_fill_gradientn(colours=matlab.like(15), labels = scales::percent, limits=rng)+ scale_x_continuous(position = &quot;top&quot;)+ labs(fill = &quot;Change in\\nSafe Winter Chill\\nsince 1975&quot;) + scale_y_discrete(labels=model_labels) + ylab(&quot;Chill metric&quot;) chill_comp_plot = (p_past + p_future + plot_layout(guides = &quot;collect&quot;,nrow=2, heights=c(1,2))) &amp; theme(legend.position = &quot;right&quot;,strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;)) chill_comp_plot 14.3 Task 3 Produce an animated line plot of your results (summarizing Safe Winter Chill across all the GCMs). hist_results = results[which(results$GCM==&quot;none&quot;),] hist_results$RCP = &quot;RCP4.5&quot; hist_results_2 = hist_results hist_results_2$RCP = &quot;RCP8.5&quot; hist_results = rbind(hist_results,hist_results_2) future_results = results[which(!results$GCM==&quot;none&quot;),] GCM_aggregate = aggregate( future_results$SWC, by=list(future_results$Metric,future_results$RCP,future_results$Year), FUN=mean) colnames(GCM_aggregate) = c(&quot;Metric&quot;,&quot;RCP&quot;,&quot;Year&quot;,&quot;SWC&quot;) RCP_Time_series = rbind(hist_results[,c(&quot;Metric&quot;,&quot;RCP&quot;,&quot;Year&quot;,&quot;SWC&quot;)], GCM_aggregate) chill_change_plot = ggplot(data=RCP_Time_series, aes(x=Year,y=SWC,col=factor(Metric,levels=metrics))) + geom_line(lwd=1.3) + facet_wrap(~RCP,nrow=2) + theme_bw(base_size=15) + labs(col = &quot;Change in\\nSafe Winter Chill\\nsince 1975&quot;) + scale_color_discrete(labels=model_labels) + scale_y_continuous(labels = scales::percent) + theme(strip.background = element_blank(), strip.text = element_text(face = &quot;bold&quot;)) + ylab(&quot;Safe Winter Chill&quot;) chill_change_plot # Create Animation p = chill_change_plot + transition_reveal(Year) #animate(p, renderer = gifski_renderer()) #anim_save(&quot;Result/chill_comparison_animation.gif&quot;, animation = last_animation()) library(magick) animation = image_read(&quot;Result/chill_comparison_animation.gif&quot;) image_animate(animation) "],["heatmaps.html", "Chapter 15 Heatmaps", " Chapter 15 Heatmaps In the previous lecture, the concept of chill and the expected changes were effectively demonstrated using heatmaps. In this chapter, this visualization method is utilized to depict the temperature measurements taken in July 2022 at the weather station in Zülpich-Fuessenich. Preprocessing is necessary for this purpose. One challenge involves categorizing the temperatures into classes. To gain an understanding of how the classes can be set within the temperature data, one can initially use the make_classes function to get an overview. make_classes &lt;- function(data, scale_) { data &lt;- as_tibble(data) min = min(data) - 1 max = max(data) sacle = scale_ end = round(((max - min) / sacle)) data[, &quot;class&quot;] &lt;- NA for (i in seq(1, nrow(data[, 1]))) { for (j in seq(0, (end - 1))) { if (data[, 1][i,] &gt; (min + end * sacle)) { data[, &quot;class&quot;][i,] = paste((min + end * sacle),&quot; &gt;&quot;) break } if (data[, 1][i,] &gt;= (min + (j * sacle)) &amp;&amp; data[, 1][i,] &lt;= ((min + sacle) + (j * sacle))) { data[, &quot;class&quot;][i,] = paste((min + (j * sacle)),&quot;-&quot;, ((min + sacle) + (j * sacle))) break } } } return(list(data, unique(data[,&quot;class&quot;]), table(data[,&quot;class&quot;]))) } First let’s load some Data weather_fue &lt;- read_delim(&quot;/Users/Phil/Documents/Auswertung_Manuel_Juli_22/temp_hum_pres08.08.22.csv&quot;) mod_weather_fue &lt;- weather_fue %&gt;% filter(&quot;2022-07-01 00:00:00&quot; &lt; date) %&gt;% filter(&quot;2022-08-01 00:00:00&quot; &gt; date) %&gt;% select(temperature, period, type, date, sensor) %&gt;% filter(period == 1, type == 0, sensor == 0) The function make_classes() is not part of the chillR package, and has thus been implemented here. It does not accept any data field as input. The temperatures must be passed directly, similar to the max() function, which is implemented by default in R. The scale_ argument must be used to specify the class width. A small demonstration of the function will be shown below. The function returns a list with multiple elements. The first list entry simply returns all the formed classes. The second entry provides an overview of the classes that were used. The third entry shows how frequently each class is represented. df = mod_weather_fue df[, &quot;class&quot;] = make_classes(df$temperature, scale_ = 2)[[1]][, 2] kable(df[1:30,], caption = &quot;Dataset Weather Fuessenich with Classes&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;,font_size = 10)%&gt;% scroll_box(width = &quot;100%&quot;) Table 15.1: Dataset Weather Fuessenich with Classes temperature period type date sensor class 13.760000 1 0 2022-06-30 23:00:00 0 13.235 - 15.235 13.698333 1 0 2022-07-01 00:00:00 0 13.235 - 15.235 13.351667 1 0 2022-07-01 01:00:00 0 13.235 - 15.235 12.951667 1 0 2022-07-01 02:00:00 0 11.235 - 13.235 12.410000 1 0 2022-07-01 03:00:00 0 11.235 - 13.235 11.958333 1 0 2022-07-01 04:00:00 0 11.235 - 13.235 11.673333 1 0 2022-07-01 05:00:00 0 11.235 - 13.235 11.923333 1 0 2022-07-01 06:00:00 0 11.235 - 13.235 12.876667 1 0 2022-07-01 07:00:00 0 11.235 - 13.235 14.400000 1 0 2022-07-01 08:00:00 0 13.235 - 15.235 15.526667 1 0 2022-07-01 09:00:00 0 15.235 - 17.235 17.248333 1 0 2022-07-01 10:00:00 0 17.235 - 19.235 17.821667 1 0 2022-07-01 11:00:00 0 17.235 - 19.235 17.816667 1 0 2022-07-01 12:00:00 0 17.235 - 19.235 18.958333 1 0 2022-07-01 13:00:00 0 17.235 - 19.235 19.556667 1 0 2022-07-01 14:00:00 0 19.235 - 21.235 19.698333 1 0 2022-07-01 15:00:00 0 19.235 - 21.235 20.330000 1 0 2022-07-01 16:00:00 0 19.235 - 21.235 21.313333 1 0 2022-07-01 17:00:00 0 21.235 - 23.235 20.411667 1 0 2022-07-01 18:00:00 0 19.235 - 21.235 19.918333 1 0 2022-07-01 19:00:00 0 19.235 - 21.235 20.028333 1 0 2022-07-01 20:00:00 0 19.235 - 21.235 17.160000 1 0 2022-07-01 21:00:00 0 15.235 - 17.235 14.213333 1 0 2022-07-01 22:00:00 0 13.235 - 15.235 12.551667 1 0 2022-07-01 23:00:00 0 11.235 - 13.235 12.090000 1 0 2022-07-02 00:00:00 0 11.235 - 13.235 11.640000 1 0 2022-07-02 01:00:00 0 11.235 - 13.235 11.148333 1 0 2022-07-02 02:00:00 0 9.235 - 11.235 10.598333 1 0 2022-07-02 03:00:00 0 9.235 - 11.235 9.701667 1 0 2022-07-02 04:00:00 0 9.235 - 11.235 In this case, a new column named class is first written in the dataframe df. The generated classes are then directly written into this column. The formed classes can now be read in the table “Dataset Weather Fuessenich with Classes” in the class column. At this point, it must be noted that the current approach is for orientational purposes only. In this particular case, the class boundaries will be manually generated at a later time using the mutate() function from the tidyverse package. The overall goal is to later provide a function that integrates the make_classes() function and automatically creates a heatmap that can be dynamically modified. # preprocessing # create column with date mod_weather_fue[,&quot;date_new&quot;] = as.POSIXct(mod_weather_fue$date, format =&quot;%m/%d/%Y %H:%M:%S&quot; ) # separate hours (time) mod_weather_fue[, &quot;hours&quot;] = format(mod_weather_fue$date_new, format = &quot;%H:%M:%S&quot;) # pick only hours mod_weather_fue[, &quot;hours_only&quot;] = as.numeric(substr(mod_weather_fue$hours, 1, 2)) # delete first row (individual fix) mod_weather_fue = mod_weather_fue[-c(1), ] # pick day mod_weather_fue[, &quot;Tag&quot;] = as.numeric(substr(mod_weather_fue$date, 9, 10)) # set new col Index with NA mod_weather_fue[,&quot;Index&quot;] &lt;- NA m3 &lt;- mod_weather_fue m3[,&quot;countfactor&quot;] &lt;- NA m1 &lt;-m3 %&gt;% # convert state to factor and reverse order of levels mutate(Index=factor(Index, levels=rev(sort(unique(Index)))))%&gt;% mutate(countfactor=cut(temperature, breaks=c(8, 10, 12, 14, 16, 18, 20, 22, 24,26,28,30,32,34,36, max(temperature, na.rm=TRUE)), labels=c(&quot;8-10&quot;, &quot;10-12&quot;, &quot;12-14&quot;, &quot;14-16&quot;, &quot;16-18&quot;, &quot;18-20&quot;, &quot;20-22&quot;,&quot;22-24&quot;,&quot;24-26&quot;,&quot;26-28&quot;,&quot;28-30&quot;, &quot;30-32&quot;,&quot;32-34&quot;,&quot;34-36&quot;,&quot;36 &gt;&quot;)))%&gt;% mutate(countfactor=factor(as.character(countfactor), levels=rev(levels(countfactor)))) colors &lt;- c(&quot;#002565&quot;, &quot;#00556E&quot;, &quot;#007763&quot;, &quot;#007F3A&quot;, &quot;#00860D&quot;,&quot;#198C00&quot;,&quot;#519300&quot;,&quot;#8B9803&quot;,&quot;#9D7608&quot;,&quot;#9A520B&quot;,&quot;#98300D&quot;,&quot;#951010&quot;,&quot;#931231&quot;,&quot;#901551&quot;,&quot;#8B1A89&quot;) textcol &lt;- &quot;grey40&quot; ggplot(m1, aes(x=hours_only , y=Tag, fill=countfactor ))+ geom_tile(colour=&quot;white&quot;, size=0.3)+ geom_text(aes(label=round(temperature, digits = 1)), size=2.3)+ scale_fill_manual(values=rev(colors), na.value = &quot;grey90&quot;)+ guides(fill=guide_legend(title=&quot;Temperatur in [°C]&quot;))+ theme_grey(base_size=10)+ labs(x = &quot;Hour&quot;, y = &quot;Day&quot;)+ ggtitle(&quot;Hourly mean Temperatures in Juli 2022&quot;)+ theme(legend.position=&quot;bottom&quot;, legend.direction=&quot;horizontal&quot;, legend.title=element_text(colour=textcol), legend.margin=margin(grid::unit(0, &quot;cm&quot;)), legend.text=element_text(colour=textcol, size=7, face=&quot;bold&quot;), legend.key.height=grid::unit(0.8, &quot;cm&quot;), legend.key.width=grid::unit(0.2, &quot;cm&quot;), axis.text.x=element_text(size=10, colour=textcol), axis.text.y=element_text(vjust=0.2, colour=textcol), axis.ticks=element_line(size=0.4), plot.background=element_blank(), panel.border=element_blank(), plot.margin=margin(0.7, 0.4, 0.1, 0.2, &quot;cm&quot;), plot.title=element_text(colour=textcol, hjust=0, size=14, face=&quot;bold&quot;) )+ scale_x_continuous(breaks = seq(from = 0, to = 23, by = 6))+ scale_y_continuous(breaks = seq(0,31,1)) As seen, it can be somewhat tricky to save the final map in a suitable format. Therefore, the entire map was saved once, and the result was read in as a whole to maintain readability. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
