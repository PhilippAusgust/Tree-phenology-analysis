[["index.html", "Learning LogBook Tree phenology analysis with R Chapter 1 Introduction", " Learning LogBook Tree phenology analysis with R Philipp Münker 2022-12-28 Chapter 1 Introduction In this learning Logbook, all units from the Tree phenology analysis with R module are documented. In addition to the tasks set at the end of each learning unit, this work is supplemented with additional materials and analyses. This is done using weather data taken from my own weather station. The corresponding data can be found at the following link: https://wettermuehle.de. Access data can be requested if desired. "],["tree-phenology.html", "Chapter 2 Tree phenology", " Chapter 2 Tree phenology If we consider fruit trees, their annual cycle can generally be described relatively easily. Starting in autumn, it is observed that almost all fruit trees shed their leaves and go into winter without foliage. Already in the autumn, the formation of the bud can often be observed. This bud then remains in a kind of winter dormancy throughout the winter and begins to grow with increasing temperatures in the spring. This process is usually followed by the flowering of the fruit trees with subsequent leaf development. Later in the year, fruits establish themselves from the buds, which mature at different times of the year. But how does the tree know when it can begin flowering induction and no longer expect strong frost? This can be described with the concept of dormancy. This can be divided into 4 phases. Tree dormancy Dormancy establishment Endodormancy Ecodormancy Growth resumption Dormacy establishment Controlled by tempeature and photoperiod. Endodormancy Controlled by plant endogenous factors. Plants unable to growth even under favorable environmental conditions. Ecodormancy After a certain level of chill, endodormancy has been overcome and buds recover the capacity to grow. Trees become acclimated to freezing tolerance and are not deeply dormant, but growth is still prevented by unsuitable environmental conditions. Temperature is the most important driver in this process. "],["treedormancy.html", "Chapter 3 Tree dormancy 3.1 Task 1 3.2 Task 2 3.3 Task 3", " Chapter 3 Tree dormancy 3.1 Task 1 Put yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods? Please justify your answer. Long-term phenological data does not exist, so a statistical approach is not optimal for newly released cultivars. It is better to work with an empirical approach. To do this, collect flower buds and place shoots in a chamber for 10 days under favorable conditions (temperature between 20 and 25 degrees). After 10 days, measure the weight of the shoots in the chamber and the shoots without the chamber. If the weight difference is greater than 30%, the cultivar is considered non-dormant. Otherwise, it is considered dormant 3.2 Task 2 Which are the advantages (2) of the BBCH scale compared with earlies scales? Not all parts of a tree are in the same development stage. Early scales only record the predominant state of the fruit tree. General principles for the design of a scale for plant growth stages include: Growth stages are easily recognizable under field conditions Growth stages are graded in the order of appearance (early scales do not do this) Two-digit code: Principal growth stages | Secondary growth stages Applicable for all cereals in all parts of the world. (Old scales can only be used for a specific group/fruit) 3.3 Task 3 Classify the following phenological stages of sweet cherry according to the BBCH scale: Picture 1 BBCH =55; Picture 2 BBCH =67; Picture 3 BBCH =89 "],["climate-change-and-impact-projection.html", "Chapter 4 Climate change and impact projection 4.1 Task 1 4.2 Task 2", " Chapter 4 Climate change and impact projection 4.1 Task 1 List the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate Table 4.1: Drivers of Climate Change Drivers of climate change Sun Aerosols Clouds Ozone Surface albedo Greenhouse gases The most important factor that currently has the greatest influence on climate and climate change is greenhouse gases. The most important greenhouse gases are water vapor, (carbon dioxide) CO2, (methane) CH4, and (nitrous oxides) N2O. Greenhouse gases can only absorb radiation of certain wavelengths. They absorb radiation with long wavelengths, which comes from the Earth’s surface in the form of infrared radiation emitted by the warm Earth’s surface. This radiation cannot leave the atmosphere and is trapped by the greenhouse gases, which returns it back to the Earth. 4.2 Task 2 Explain briefly what is special about temperature dynamics of the recent decades, and why we have good reasons to be concerned Over the past decades and throughout the last century, the temperature has been rising worldwide. Initially, this increase was relatively slow. The ten warmest years worldwide since 1880 were all measured after the millennium. The five warmest years worldwide were all recorded after 2014. This effect is also noticeable in Germany. Here, too, the ten warmest years were all measured after 2000, with one exception. If one places the temperature increase of the last decades in the climate history of the last one million years, it can be seen that there has never been such a strong temperature increase over such a relatively short period of time. This rapid rise in temperature is developing its own dynamic. For example, high temperatures in the tundra cause the permafrost to thaw, releasing a large amount of CO2, a greenhouse gas that promotes even faster warming. "],["manual-chill-analysis.html", "Chapter 5 Manual Chill Analysis 5.1 Task 1 5.2 Task 2 5.3 Task 3", " Chapter 5 Manual Chill Analysis The Winters_hours_gaps data set has the columns: Year, Month, Day, Hour, Temp_gaps, Temp. First, the function cleaned_data is used to remove unnecessary columns such as Temp_gaps() from the data set. #Clean Function cleaned_data = function(data_source) { data_source = data_source[, c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;, &quot;Hour&quot;, &quot;Temp&quot;)] return(data_source) } # Apply Function to Winters_hours_gaps kable(head(cleaned_data(data_source = Winters_hours_gaps)), &quot;pipe&quot;, caption = &quot;Cleaned Dataset: Winters_hours_gaps&quot;) Table 5.1: Cleaned Dataset: Winters_hours_gaps Year Month Day Hour Temp 2008 3 3 10 15.127 2008 3 3 11 17.153 2008 3 3 12 18.699 2008 3 3 13 18.699 2008 3 3 14 18.842 2008 3 3 15 19.508 5.1 Task 1 Write a basic function that calculates warm hours (&gt;25°C) WH = function(hourtemps) { hourtemps[, &quot;warm_hours&quot;] &lt;- hourtemps$Temp &gt;= 25.0 return(hourtemps) } 5.2 Task 2 Apply this function to the Winters_hours_gaps dataset # have a look to the data set kable(head(Winters_hours_gaps), &quot;pipe&quot;, caption = &quot;Example Dataset: Winters_hours_gaps&quot;) Table 5.2: Example Dataset: Winters_hours_gaps Year Month Day Hour Temp_gaps Temp 2008 3 3 10 15.127 15.127 2008 3 3 11 17.153 17.153 2008 3 3 12 18.699 18.699 2008 3 3 13 18.699 18.699 2008 3 3 14 18.842 18.842 2008 3 3 15 19.508 19.508 # Apply Function hourtemps = cleaned_data(data_source = Winters_hours_gaps) kable(head(WH(hourtemps = hourtemps)), &quot;pipe&quot;) Year Month Day Hour Temp warm_hours 2008 3 3 10 15.127 FALSE 2008 3 3 11 17.153 FALSE 2008 3 3 12 18.699 FALSE 2008 3 3 13 18.699 FALSE 2008 3 3 14 18.842 FALSE 2008 3 3 15 19.508 FALSE 5.3 Task 3 Extend this function, so that it can take start and end dates as inputs and sums up warm hours between these dates warm_hours_function = function(Input_Data, S_Jahr, S_Monat, S_Tag, S_Stunde, E_Jahr, E_Monat, E_Tag, E_Stunde) { Start_Date &lt;- which( hourtemps$Year == S_Jahr &amp; hourtemps$Month == S_Monat &amp; hourtemps$Day == S_Tag &amp; hourtemps$Hour == S_Stunde ) End_Date &lt;- which( hourtemps$Year == E_Jahr &amp; hourtemps$Month == E_Monat &amp; hourtemps$Day == E_Tag &amp; hourtemps$Hour == E_Stunde ) # Apply Function Warm Hours (WH) hourtemps = WH(hourtemps = Input_Data) # Calculate warm_hours warm_hours = sum(hourtemps$warm_hours[Start_Date:End_Date]) return(cat(&quot;The number of heat hours is:&quot;, paste(warm_hours))) } warm_hours_function( Input_Data = hourtemps, S_Jahr = 2008, S_Monat = 5, S_Tag = 1, S_Stunde = 12, E_Jahr = 2008, E_Monat = 8, E_Tag = 31, E_Stunde = 12 ) ## The number of heat hours is: 957 "],["chill-models.html", "Chapter 6 Chill Models 6.1 Task 1 6.2 Task2 6.3 Task3", " Chapter 6 Chill Models Counting chill hours can be done in various ways. ChillR offers some functions for this purpose. The simplest function for this is the Chilling_Hours() function. It records one chill hour for every temperature between 0 and 7.2 degrees. A slightly more complex function is the Utah_Model() function. It evaluates the measured temperatures and decides whether a full chill hour was reached or only half. For example, if the temperature is between 1 and 2 degrees, one chill hour has been reached. If it is between 3 and 4 degrees, two chill hours are recorded. The Dynamic_model() function is the most complex function. It is taken from an Excel sheet. The chilling() function combines the functions described above and presents the results in an overview. 6.1 Task 1 Run the chilling() function on the Winters_hours_gap dataset # run chilling function on Winters_hours_gap dataset output = chilling(make_JDay(Winters_hours_gaps), Start_JDay = 90, End_JDay = 100) kable(output, caption =&quot;chilling function on Winters_hours_gap&quot;) %&gt;% kable_classic_2(full_width = F, font_size = 7) Table 6.1: chilling function on Winters_hours_gap Season End_year Season_days Data_days Perc_complete Chilling_Hours Utah_Model Chill_portions GDH 2007/2008 2008 11 11 100 40 15.5 2.009147 2406.52 6.2 Task2 Create your own temperature-weighting chill model using the step_model() function The step_model function has two arguments that the user can pass. One is a dataset of temperature data HourTemp and the other is a data.frame() (df) consisting of lower, upper, and weight. A pre-defined lower temperature range from, for example, -1000 °C to 0 °C is set, with all temperatures within this range being assigned a weight of 0. Assuming that hourly temperature data is provided as input, the temperature can be multiplied by the corresponding weight to obtain the amount of “chillhours”. For example: -1 °C is within the range [-1000, 0] == 0, resulting in 0 chillhours. Another argument is summ. If summ = TRUE, the cumulative chillhours over a defined period will be output. If summ = FALSE, the weights of the chillhours will be output. step_model = function (HourTemp, df = data.frame( lower = c(-1000, 1.4, 2.4, 9.1, 12.4, 15.9, 18), upper = c(1.4, 2.4, 9.1, 12.4, 15.9, 18, 1000), weight = c(0, 0.5, 1, 0.5, 0, -0.5, -1) ), summ = TRUE) { lower &lt;- df$lower upper &lt;- df$upper weight &lt;- df$weight if (summ == TRUE) return(cumsum(sapply(HourTemp, function(x) weight[which(x &gt; lower &amp; x &lt;= upper)]))) else return(sapply(HourTemp, function(x) weight[which(x &gt; lower &amp; x &lt;= upper)])) } Here, only an “own data field” is defined with its own limits that have their own weight. For example, from -100 °C to 0 °C, the weight is set to 0. In this case, no “chillhour” occurs. If the temperature is between 0 °C and 2 °C, the weight of the “chillhour” is 0.5. In this case, half a “chillhour” occurs. own_df = data.frame (lower = c(-100,0, 2, 4, 5, 6, 7 ), upper = c( 0, 2, 4, 5, 6, 7, 100 ), weight = c( 0, 0.5,1, 1.5,1, 0.5, 0 )) After the dataframe with your own weights has been created, it can be implemented into the step_model() function. use_step_model = function(x){step_model(x,own_df)} # quick aplly use_step_model(x = Winters_hours_gaps$Temp)[1:100] ## [1] 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.5 ## [16] 1.0 1.0 1.0 1.5 2.5 3.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 ## [31] 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 ## [46] 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 4.5 ## [61] 4.5 5.0 5.5 6.0 7.0 8.5 9.5 10.5 11.5 12.5 13.0 13.0 13.0 13.0 13.0 ## [76] 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.5 14.0 15.0 16.5 18.0 ## [91] 19.5 21.0 22.0 23.0 23.0 23.0 23.0 23.0 23.0 23.0 6.3 Task3 Run this model on the Winters_hours_gaps dataset using the tempResponse() function The tempResponse() function can display and summarize some chill models. Here is the model weather_mill() our own chilling model which is created by the step_model(). The modified step_model() function is renamed to use_step_model() and passed as a parameter to the tempResponse function (weather_mill = use_step_model). output &lt;- tempResponse( make_JDay(Winters_hours_gaps), Start_JDay = 30, End_JDay = 100, models = list( Chill_Portions = Dynamic_Model, GDH = GDH, weather_mill = use_step_model, # own model weather_mill Utah_Model = Utah_Model ) ) # display result kable(output, caption = &quot;Summarized some models&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 7) Table 6.2: Summarized some models Season End_year Season_days Data_days Perc_complete Chill_Portions GDH weather_mill Utah_Model 2007/2008 2008 71 37.58333 52.93427 5.930439 8392.585 84 49.5 If the Utah Model is included, which is based on the default settings of the Step Model, a clear difference between the modified Step Model and the Utah Model can be observed. "],["making-hourly-temperatures.html", "Chapter 7 Making hourly temperatures 7.1 Task 1 7.2 Task 2", " Chapter 7 Making hourly temperatures 7.1 Task 1 Choose a location of interest, find out its latitude and produce plots of daily sunrise, sunset and daylength First, I would like to compare the lengths of days among locations of interest. I have selected Glogau in Poland, Zülpich in Germany, Tenerife in Spain, Moscow in Russia, and Karkaralinsk in Kazakhstan. # initialize the variables with daylength, sunrise and sunset by the function daylength Glogau &lt;- daylength(latitude = 51.40, JDay = 1:365) Teneriffa &lt;- daylength(latitude = 28.19, JDay = 1:365) Zuelpich &lt;- daylength(latitude = 50.42, JDay = 1:365) Moskau &lt;- daylength(latitude = 55.45, JDay = 1:365) Karkaralinsk &lt;- daylength(latitude = 49.24, JDay = 1:365) # Create a dataframe consisting of the variables &quot;base&quot; (days 1 to 365) and the # respective locations and containing only the day length for each location. df &lt;- data.frame( base = seq(length(Glogau[[1]])), Glogau = Glogau[[3]], Teneriffa = Teneriffa[[3]], Zülpich = Zuelpich[[3]], Moskau = Moskau[[3]], Karkaralinsk = Karkaralinsk[[3]] ) kable(head(df), caption = &quot;Differnt Locations&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 7) Table 7.1: Differnt Locations base Glogau Teneriffa Zülpich Moskau Karkaralinsk 1 7.930050 10.38197 8.086864 7.175796 8.265160 2 7.948054 10.38872 8.104044 7.198073 8.281428 3 7.967737 10.39612 8.122830 7.222407 8.299217 4 7.989077 10.40415 8.143199 7.248768 8.318509 5 8.012048 10.41281 8.165129 7.277120 8.339282 6 8.036625 10.42209 8.188595 7.307424 8.361515 # create a pivot table df_long &lt;- pivot_longer(df, -&quot;base&quot;, names_to = &quot;Location&quot;, values_to = &quot;daylength&quot;) kable(head(df_long)) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) base Location daylength 1 Glogau 7.930050 1 Teneriffa 10.381965 1 Zülpich 8.086864 1 Moskau 7.175796 1 Karkaralinsk 8.265160 2 Glogau 7.948054 # plot the result with ggplot ggplot(df_long, aes(x = base, y = daylength, groupe = Location)) + geom_line(aes(color = Location), lwd = 1.0) + ggtitle(&quot;Different day lengths in different places&quot;) + labs(x = &quot;Days&quot;, y = &quot;Daylength [h]&quot;) + theme_gray(base_size = 15) Create a summary of the sunrise, sunset, and day length for Moscow. Days &lt;- daylength(latitude = 55.45, JDay = 1:365) Days_df &lt;- data.frame( JDay = 1:365, Sunrise = Days$Sunrise, Sunset = Days$Sunset, Daylength = Days$Daylength ) Days_df&lt;-melt(Days_df, id=c(&quot;JDay&quot;)) Show the final result ggplot(Days_df, aes(x = JDay, y = value)) + geom_line(lwd = 1.5, color = &quot;red&quot;) + facet_grid(cols = vars(variable)) + ylab(&quot;Time of Day / Daylength (Hours)&quot;) + theme_bw(base_size = 20) + ggtitle(&quot;Sunrise, Sunset and Daylength of Moskau&quot;) 7.2 Task 2 Produce an hourly dataset, based on idealized daily curves, for the KA_weather dataset (included in chillR) The following two tasks were performed in a modified form. In order to demonstrate the application of the chillR package, it was decided to use a currently active weather station and use its data as a basis. Data on the weather station can be found in the table below. Table 7.2: Weather Station Fuessenich Location State GPS Gauß_Krüger Zuelpich - Fuessenich North Rhine-Westphalia 50.69527026369208, 6.615666577711913 Rechtswert:2543500 Hochwert: 5617798 First, corresponding data must be read in. The data are already prepared. Zuelpich_hourly = read.table( &quot;weather_data/Weather_Zuelpich_2019_hourly.csv&quot;, header = TRUE, sep = &quot;,&quot; ) Zuelpich_min_max = read.table(&quot;weather_data/Weather_Zuelpich_2019.csv&quot;, header = TRUE, sep = &quot;,&quot;) zuelpich_april = Zuelpich_hourly %&gt;% filter(&quot;2019-04-01 00:00:00&quot; &lt; date) %&gt;% filter(&quot;2019-04-05 00:00:00&quot; &gt; date) zuelpich_april$date_new &lt;- as.POSIXct(zuelpich_april[, 3]) zuelpich_april$date_newnew = as.Date(zuelpich_april[, 3]) kable(head(zuelpich_april), caption = &quot;Dataset: zuelpich_april&quot;) %&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) Table 7.3: Dataset: zuelpich_april X temperature date date_new date_newnew 1412 3.4350000 2019-04-01 01:00:00 2019-04-01 01:00:00 2019-04-01 1413 2.0900000 2019-04-01 02:00:00 2019-04-01 02:00:00 2019-04-01 1414 1.2616667 2019-04-01 03:00:00 2019-04-01 03:00:00 2019-04-01 1415 0.6150000 2019-04-01 04:00:00 2019-04-01 04:00:00 2019-04-01 1416 0.0583333 2019-04-01 05:00:00 2019-04-01 05:00:00 2019-04-01 1417 -0.3566667 2019-04-01 06:00:00 2019-04-01 06:00:00 2019-04-01 Next, the lows and highs for the corresponding days must be determined from the data set containing hourly data. final &lt;- zuelpich_april %&gt;% group_by(Tag = day(date_newnew)) %&gt;% summarise( Mittel = round(mean(temperature, na.rm = TRUE), digits = 1), Tmax = max(temperature), Tmin = min(temperature) ) kable(final, caption = &quot;Dataset:Tmean Tmax Tmin&quot;)%&gt;% kable_styling(&quot;striped&quot;, position = &quot;left&quot;, font_size = 10) Table 7.4: Dataset:Tmean Tmax Tmin Tag Mittel Tmax Tmin 1 7.7 17.810000 -0.420000 2 9.5 17.096667 2.693333 3 7.6 9.983333 5.481667 4 5.7 7.763333 3.566667 Next, the dataset containing hourly temperature values must be extended with a column that will later represent the daily high and low values. First, the new column Tmax_Tmin is filled with “NAs”. Then the maximum and minimum values are taken from the previously generated dataset final. These values are compared with the hourly values. If they match, the maximum or minimum value found is written to the previously created column Tmax_Tmin. In this way, the daily maximum and minimum values are placed in the table zuelpich_april at the same place where they were also measured. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
