---
title: "Learning Logbook"
author: "Philipp Münker"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: yes
    toc_float: yes
    code_folding: hide
    numbered: yes
    theme: journal
    number_figures: true
---



<style>
body {
text-align: justify}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Tree dormacy 

* Dormacy establishment
* Endodormancy
* Ecodormancy
* Growth resumption


##### Dormacy establishment

Controlled by tempeature and photoperiod. 

##### Endodormancy

Controlled by plant endogenous factors. Plants unable to growth even under 
favorable environmental conditions. 

##### Ecodormancy

After a certain level of chill endodormancy has been overcome. 
Buds recover capacity to growth. Tree is aclimated freezing tolerance - not deeply
dormant. Growth is prevented by unsuitable environmental conditions. Temperature is 
the most important driver

### Task 1
##### 1. Put yourself in the place of a breeder who wants to calculate the temperature requirements of a newly released cultivar. Which method will you use to calculate the chilling and forcing periods? Please justify your answer.

Long penolocigal data does not exist => statistically approach is not optimal for newly released cultivar. 
It is better to work with the empirically approach. Collect Flower buds => take shoots and place them in a chamber for 10 days under 
favorable conditions (Temperature between 20 and 25 degrees) => After 10 days measure weight of shoots in chamber and shoots without chamber => If weight difference is bigger than 30 percent => Non dormant else => dormant 


### Task 2
##### 2. Which are the advantages (2) of the BBCH scale compared with earlies scales?

Not all the parts of a tree presents the same development sate. Early scales record only the 
Predominat state of the fruit tree. 
General principles for the design of a scale for plant growth stages: 

* Growth stages easily recognizable under fiels conditions

* Growth stages graded in the order of appearance (Early scale dont do that)

* Tow digit code: Principal growth stages| Secondary growth stages

* Aplicable for all cereals in all parts of the world. (Old scales can only used for a special grop/fruit)


### Task 3
##### Classify the following phenological stages of sweet cherry according to the BBCH scale:

![Picture 1 BBCH =55;  Picture 2 BBCH =67;  Picture 3 BBCH =89](./pheno_stages.png)





### Climate change and impact projection

### Task 1

##### List the main drivers of climate change at the decade to century scale, and briefly explain the mechanism through which the currently most important driver affects our climate. 



```{r,echo=FALSE}
library(readxl)
mod <- read_excel("Drivers of Climate Change.xlsx")
knitr::kable(head(mod), "pipe", caption = "Drivers of Climate Change")
```

The most important factor that currently has the greatest influence on climate and climate change is greenhouse gases.
The most important greenhouse gases are water vapour, (carbon dioxide) CO<sub>2</sub>, (methane) CH<sub>4</sub> and (nutrios oxides) N<sub>2</sub>O.Greenhouse gases can absorb only radiation of certain wavelengths. They absorb radiation with long wavelength, which comes from the earth surface. Infrared radiation which is emitted by warm earth surface. This radiation can not leave the atmosphere and is trapped by the greenhousgases and returns back to earth.  

### Task 2

##### Explain briefly what is special about temperature dynamics of the recent decades, and why we have good reasons to be concerned

Over the past decades and the whole of the last century, the temperature has been rising worldwide. Initially, this increase was relatively slow. 
The ten warmest 10 years worldwide since 1880 were all measured after the millennium. The five warmest years worldwide were all recorded after 2014. 
This effect is also noticeable in Germany. Here, too, the ten warmest years were all measured after 2000, with one exception. 
If one places the temperature increase of the last decades in the climate history of the last 1 million years, it can be seen that there has never been such a strong temperature increase over such a relatively short period of time.  
This rapid rise in temperature is developing an additional dynamic of its own. For example, high temperatures in the tundra cause the permafrost to thaw, which in turn releases a large amount of C0<sub>2</sub>, a greenhouse gas that promotes even faster warming. 



```{r, echo = FALSE}
 
```





### Manual Chill Analysis

### Task 1

```{r, message=FALSE,echo= FALSE}

library(tidyverse)
library(chillR)
library(knitr)
library(pander)
library(kableExtra)

```



```{r, echo=TRUE}
  
  #Clean Function
  
  cleaned_data = function(data_source){
  data_source = data_source[,c("Year","Month","Day","Hour","Temp")]
  return(data_source)  
  }

  # Apply Function to Winters_hours_gaps

  kable(head(cleaned_data(data_source = Winters_hours_gaps)),"pipe")


```



##### Write a basic function that calculates warm hours (>25°C)

```{r}
 
  WH<-function(hourtemps)
  {
    hourtemps[,"warm_hours"]<-hourtemps$Temp>=25.0
    return(hourtemps)
  }
```

### Task 2

##### Apply this function to the Winters_hours_gaps dataset

```{r, echo=TRUE}
# have a look to the data set
kable(head(Winters_hours_gaps), "pipe", caption = "Example Dataset: Winters_hours_gaps") 



```


```{r,}

# Apply Function 

 
hourtemps = cleaned_data(data_source=Winters_hours_gaps)
kable(head(WH(hourtemps = hourtemps)), "pipe")

```

### Task 3

##### Extend this function, so that it can take start and end dates as inputs and sums up warm hours between these dates





```{r}


warm_hours_function= function(Input_Data,S_Jahr,S_Monat,S_Tag, S_Stunde, E_Jahr,E_Monat,E_Tag, E_Stunde){


Start_Date<-which(hourtemps$Year== S_Jahr& hourtemps$Month==S_Monat &
                    hourtemps$Day==S_Tag & hourtemps$Hour==S_Stunde)
End_Date<-which(hourtemps$Year==E_Jahr & hourtemps$Month==E_Monat &
                  hourtemps$Day==E_Tag & hourtemps$Hour==E_Stunde)

# Apply Function Warm Hours (WH)
hourtemps= WH(hourtemps = Input_Data)

# Calculate warm_hours
warm_hours = sum(hourtemps$warm_hours[Start_Date:End_Date])


return(cat("The number of heat hours is:", paste(warm_hours)))

}

warm_hours_function(Input_Data=hourtemps,S_Jahr=2008,S_Monat=5,S_Tag=1,12,2008,8,31,12)


```
### Chill models

### Task 1

#### Run the chilling() function on the Winters_hours_gap dataset


```{r}

# run chilling function on Winters_hours_gap dataset 
output<-chilling(make_JDay(Winters_hours_gaps),Start_JDay = 90, End_JDay = 100)

# display result
kable(output)%>%
  kable_styling("striped", position = "left", font_size = 10)
```


### Task 2

#### Create your own temperature-weighting chill model using the step_model() function

```{r, echo= TRUE}
# have a look at the step model function

# Die Step Model Funktion besitzt zwei Argumente, die der Nutzer übergeben kann. 
# Einmal kann ein Datenset mit Temperaturdaten übergeben werden. 
# Hierfür steht das Argument HourTemp. 
# Dem Argument df kann ein data.frame übergeben werden. 
# Dies data.frame besteht aus lower, upper und weight. 
# Vordefiniert ist ist eine untere Temperaturgrenze von z.B -1000 °C bis 0 °C. 
# Alle Temperaturen, die in diesem Bereich liegen, werden dem Gewicht 0 zugeordnet. 
# Geht man davon aus, dass man stündliche Temperaturdaten als Input zur Verfügung stellt, 
# kann man die Temperatur mit dem entsprechenden Gewicht multiplizieren und man erhält 
# als Ergebnis die Menge der „chillhours“. 
# Zum Beispiel : -1 °C  liegt in dem Intervall [-1000,0] == 0 => 0 chillhours. 
# Ein weiteres Argument ist summ. Ist summ = TRUE werden die kummulierten chillhours über 
# einen definierten Zeitraum ausgeben. 
# Ist summ == FASLE gesetzt werden die Gewichte der chillhours ausgegeben. 


step_model <- function (HourTemp,
                        df =
                          data.frame(
                            lower = c(-1000, 1.4, 2.4, 9.1, 12.4, 15.9, 18),
                            upper = c(1.4, 2.4, 9.1, 12.4, 15.9, 18, 1000),
                            weight = c(0, 0.5, 1, 0.5, 0,-0.5,-1)
                          ),
                        summ = TRUE)
{
  lower <- df$lower
  upper <- df$upper
  weight <- df$weight
  if (summ == TRUE)
    return(cumsum(sapply(HourTemp, function(x)
      weight[which(x >
                     lower & x <= upper)])))
  else
    return(sapply(HourTemp, function(x)
      weight[which(x >
                     lower & x <= upper)]))
}



# define own temperature weighting

# Hier wird nur ein "eigenes Datenfeld" definiert mit eigenen Grenzen, die ein 
# eigenes Gewicht besitzen. 
# Zum Beispiel wird von -100 °C bis 0 °C das Gewicht == 0 gesetzt. 
# In diesem Fall findet keine "chillhour" statt. 
# Liegt die Temperatur hingegen zwischen 0 °C und 2 °C beträgt das Gewicht der 
# "chillhour" 0.5. Hier findet einen halbe "chillhour" statt. 

own_df = data.frame (lower  = c(-100,0,  2, 4,  5, 6,   7    ),
                     upper  = c(  0, 2,  4, 5,  6, 7,   100  ),
                     weight = c(  0, 0.5,1, 1.5,1, 0.5, 0    ))


# functional

use_step_model <- function(x){step_model(x,own_df)}


# quick aplly 

use_step_model(x= Winters_hours_gaps$Temp)[1:100]

```


### Task 3

#### Run this model on the Winters_hours_gaps dataset using the tempResponse() function.

The tempResponse function can display and summarise some chill models. Here is the 
the model "weather_mill" our own chilling model which is created by the step_model_funktion.
The modified stepmodel function is renamed by use_step_model and given as a parameter 
to the tempResponse function (weather_mill = use_step_mode). 
We can see a great 

```{r}
 output<-tempResponse(make_JDay(Winters_hours_gaps),Start_JDay = 30, End_JDay = 100,        models=list(Chill_Portions=Dynamic_Model, GDH=GDH, weather_mill = use_step_model,
 Utah_Model = Utah_Model))

kable(output) %>%
  kable_styling("striped", position = "left", font_size = 10)
```
If the Utah_Model is included, which is based on the default settings of the Step_Model, a clear difference between the modified Step Model and the Utah Model can be noted. 



### Making hourly temperatures



### Task 1 

##### Choose a location of interest, find out its latitude and produce plots of daily sunrise, sunset and daylength

First, I would like to draw a comparison of day lengths among locations that interest me. I have chosen Glogau in Poland, Zülpich in Germany, Tenerife in Spain, Moscow in Russia and Karkaralinsk in Kazakhstan.


```{r, echo= TRUE}

# initialize the variables with daylength, sunrise and sunset by the function daylength
Glogau      <- daylength(latitude = 51.40, JDay = 1:365)
Teneriffa   <- daylength(latitude = 28.19, JDay = 1:365)
Zuelpich    <- daylength(latitude = 50.42, JDay = 1:365)
Moskau      <- daylength(latitude = 55.45, JDay = 1:365)
Karkaralinsk<- daylength(latitude = 49.24, JDay = 1:365)


#Create a dataframe consisting of the variables "base" (days 1 to 365) and the 
#respective locations and containing only the day length for each location.

df <- data.frame(
  base         = seq(length(Glogau[[1]])),
  Glogau       = Glogau[[3]],
  Teneriffa    = Teneriffa[[3]],
  Zülpich      = Zuelpich[[3]],
  Moskau       = Moskau[[3]],
  Karkaralinsk = Karkaralinsk[[3]]
)


kable(head(df)) %>% kable_styling("striped", position = "left", font_size = 10)

# create a pivot table
df_long <-
  pivot_longer(df,-"base", names_to = "Location", values_to = "daylength")

kable(head(df_long)) %>% kable_styling("striped", position = "left", font_size = 10)


# plot the result with ggplot
ggplot(df_long, aes(x = base, y = daylength, groupe = Location)) +
  geom_line(aes(color = Location), lwd = 1.0) +
  ggtitle("Different day lengths in different places") +
  labs(x = "Days", y = "Daylength [h]") + theme_gray(base_size = 15)


```


Sunrise, Sunset and Daylength of Moskau



```{r, echo= TRUE, warning=FALSE, message=FALSE}
require(reshape2)

Days<-daylength(latitude=55.45,JDay=1:365)

Days_df<-data.frame(JDay=1:365,Sunrise=Days$Sunrise,Sunset=Days$Sunset,Daylength=Days$Daylength)

Days_df<-melt(Days_df, id=c("JDay")) 

ggplot(Days_df, aes(x=JDay, y= value)) + geom_line(lwd=1.5, color = "red") + facet_grid(cols=vars(variable)) +
  ylab("Time of Day / Daylength (Hours)") + theme_bw(base_size = 20)+
  ggtitle("Sunrise, Sunset and Daylength of Moskau")

```


### Task 2

##### Produce an hourly dataset, based on idealized daily curves, for the KA_weather dataset (included in chillR)

The following two tasks were performed in a modified form. In order to have an application of the chillR pacjage it was decided to use a currently active weather station and use its data as a basis. Data on the weather station can be found in the following table.  


```{r, echo=FALSE}
location = data.frame(
  Location = c("Zuelpich - Fuessenich"),
  State = c("North Rhine-Westphalia"),
  GPS = c("50.69527026369208, 6.615666577711913"),
  Gauß_Krüger = c("Rechtswert:2543500 Hochwert: 5617798")
)


kable(location)%>% kable_styling("striped", position = "left", font_size = 10)

```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(chillR)
library(lubridate)
library(kableExtra)
library(reshape2)
library(ggdark)
```

First, corresponding data must be read in. The data are already prepared.

```{r, echo =TRUE}

Zuelpich_hourly = read.table(
  "weather_data/Weather_Zuelpich_2019_hourly.csv",
  header = TRUE,
  sep = ","
)

Zuelpich_min_max = read.table("weather_data/Weather_Zuelpich_2019.csv",
                              header = TRUE,
                              sep = ",")

```

The dataset Zuelpich_hourly contains for the year 2019 one temperature value for each hour. Note that the hourly temperature value represents the mean value of the respective hour. The data set starts in February

```{r, echo=FALSE}
kable(head(Zuelpich_hourly))%>% kable_styling("striped", position = "left", font_size = 10)

```

Daily highs and lows for 2019 from February

```{r,echo=FALSE}
kable(head(Zuelpich_min_max))%>% kable_styling("striped", position = "left", font_size = 10)
```

Next, a database must be generated that contains all temperature data relevant for the next steps. This is done with the filter function from the tidyverse package. In this case all temperature data from ```1.4``` to ```5.4 2019``` should be considered. Furthermore, two new columns are to be created, which contain the date once in the format ```year - month - day - hour -minute - second``` and once ```day - month - year```.

```{r,echo=TRUE}
zuelpich_april = Zuelpich_hourly %>% filter("2019-04-01 00:00:00" < date) %>%
  filter("2019-04-05 00:00:00" > date)

zuelpich_april$date_new <- as.POSIXct(zuelpich_april[, 3])
zuelpich_april$date_newnew = as.Date(zuelpich_april[, 3])

kable(head(zuelpich_april))%>% kable_styling("striped", position = "left", font_size = 10)

```

Next, the lows and highs for the corresponding days must be determined from the data set containing hourly data. 

```{r,echo=TRUE}
final <- zuelpich_april %>%
  group_by(Tag = day(date_newnew)) %>%
  summarise(
    Mittel =  round(mean(temperature, na.rm = TRUE), digits = 1),
    Tmax = max(temperature),
    Tmin = min(temperature)
  )
 
kable(final)%>% kable_styling("striped", position = "left", font_size = 10)
```



Next, the data set containing hourly temperature values must be extended by a column that later represents the daily high and low values. First, the new column ```Tmax_Tmin``` is filled with ```NAs```. Then the maximum and minimum values are taken from the previously generated data set "final". These are compared with the hourly values. If these match, the maximum or minimum value found is written to the previously created column ```Tmax_Tmin```. Thus the daily maximum and minimum values are at the place in the table ```zuelpich_april```, where they were also measured.


```{r, echo=TRUE}
# generate new coloumn with NAs 
zuelpich_april$Tmax_Tmin = NA

# match Tmin
for (i in seq(1, nrow(zuelpich_april))) {
  for (j in seq(1, nrow(final))) {
    if (zuelpich_april$temperature[i] == final$Tmax[j]) {
      zuelpich_april$Tmax_Tmin[i] <- final$Tmax[j]
    }
  }
}

# match Tmax 

for(i in seq(1, nrow(zuelpich_april))) {
  for (j in seq(1, nrow(final))) {
    if (zuelpich_april$temperature[i] == final$Tmin[j]) {
      zuelpich_april$Tmax_Tmin[i] <- final$Tmin[j]
    }
  }
}


kable(zuelpich_april[1:25,])%>% kable_styling("striped", position = "left", font_size = 10)
```


After creating a new column containing only the ```Tmax``` and ```Tmin``` temperatures, a plot can be created that contains the measured temperature history and also includes information about ```Tmax``` and ```Tmin``` . The red dots symbolize the daily temperature values for ```Tmax``` and ```Tmin``` , respectively.  


```{r,echo=TRUE, warning=FALSE, message=FALSE}

ggplot(data = zuelpich_april, aes(x = zuelpich_april[, 4], y = zuelpich_april[, 2])) +
  geom_line(size = 1.0, colour = "darkgreen") +
  geom_point(aes(y = zuelpich_april$Tmax_Tmin),
             colour = "red",
             size = 3.0) +
  labs(x = "Date", y = "Temperature (C°)") +
  ggtitle("1 to 5 April 2019 weather station Zuelpich") +
  theme_bw(base_size = 13)
  

```



The dataset ```ZU_weather``` must be created first. The columns ```DATE``` ```Year``` ```Month``` ```Day``` ```Tcontinue``` and ```Temp_inter``` are created. The ```Temp_inter``` column contains the temperature data that have large gaps and must be interpolated between. 


```{r, echo = TRUE}
ZU_weather = data.frame(
  DATE = zuelpich_april[, 4],
  Year = as.numeric(substr(zuelpich_april[, 4], 1, 4)),
  Month = as.numeric(substr(zuelpich_april[, 4], 6, 7)),
  Day = as.numeric(substr(zuelpich_april[, 4], 9, 10)),
  Tcontinue = zuelpich_april[, 2],
  Temp_inter = zuelpich_april[, 6]
)

kable(ZU_weather[1:8,])%>% kable_styling("striped", position = "left", font_size = 10,)
```



The next step is to use the ```interpolate_gaps ()``` function to calculate the missing temperatures between the ```Tmax``` and ```Tmin```. The function ``` interpolate_gaps() ``` returns a list with two entries. The first entry of the list contains the interpolated values. To select this one can use ```$interp``` or ```[[1]]```.The second entry ```$missing``` gives information whether a value must be interpolated or whether a real value is present. The function ```interpolate_gaps()``` interpolates linearly between gaps in the temperature records. The interpolated values are written directly to the ```Temp_inter``` column. As just described, the first list entry created by the ```interpolate_gaps``` function must be used for this. 



```{r, echo=TRUE}
# interpolate between gaps in coloum Temp_inter 

ZU_weather$Temp_inter<-interpolate_gaps(ZU_weather$Temp_inter)[[1]]

# have a look at the first 10 entries

kable(ZU_weather[1:10,])%>% kable_styling("striped", position = "left", font_size = 10,)

```
Thus, all gaps in the column ```Temp_inter``` are filled by a linear interpolation. The interpolation runs exactly between the gaps. 

The non-linear interpolation method includes the sun position of the respective location in the interpolation.Furthermore the function ```stack_hourly_temps()``` needs a dataset as input, which contains only the ```Tmax``` and ```Tmin``` values. In this example, this dataset is called ```ZU_weather_min_max``` and consists of five columns: ```Year```, ```Month```, ```Day```, ```Tmax``` and ```Tmin```.  

```{r, echo = TRUE}
# create dataframe for non-linear interpolation
ZU_weather_min_max = data.frame(
  Year = as.numeric(substr(Zuelpich_min_max[, 2], 1, 4)),
  Month = as.numeric(substr(Zuelpich_min_max[, 2], 6, 7)),
  Day = as.numeric(substr(Zuelpich_min_max[, 2], 9, 10)),
  Tmax = final[, 3],
  Tmin = final[, 4]
)
kable(ZU_weather_min_max[1:10,])%>% kable_styling("striped", position = "left", font_size = 10,)
```

The ```stack_hourly_temps()``` function can be passed the entire data set  ``` ZU_weather_min_max```. Note that the function 
```stack_hourly_temps()``` sets the ``` Tmax```  values to ```06:00 pm```  and ``` Tmin```  values to ``` 06:00 am```. Thus, no interpolation is done between the time when the ``` Tmax``` and ``` Tmin``` values actually occurred. The result of the interpolation is written to a new data set ``` ZU_hourly``` . Then the first list entry in the data set is selected and a new column named ```DATE``` is created to store the date. Finally, the first row is removed due to an index shift. 


```{r,echo=TRUE}
ZU_hourly = stack_hourly_temps(ZU_weather_min_max, latitude = 50.4)

ZU_hourly$hourtemps[, "DATE"] =
  ISOdate(
    ZU_hourly$hourtemps$Year,
    ZU_hourly$hourtemps$Month,
    ZU_hourly$hourtemps$Day,
    ZU_hourly$hourtemps$Hour
  )


ZU_hourly_mod = ZU_hourly[[1]][-1, ]


kable(ZU_hourly_mod[1:10,])%>% kable_styling("striped", position = "left", font_size = 10,)
```


Finally, a data set is generated containing the actual measured temperature data and additionally the interpolated values calculated once by a linear interpolation and once by a non-linear interpolation. The result can be well displayed in a plot.  





```{r, echo = TRUE, message=FALSE, warning= FALSE}
# final_df = data.frame(
#   DATE = zuelpich_april[, 4],
#   Measured_Temp = zuelpich_april[, 2],
#   Linear_Interp  = ZU_weather[, 6],
#   Non_Linear_Interp = ZU_hourly_mod[, 8]
# )
#write.csv(final_df, "weather_data/final_df_non_linear.csv")

# read final dataframe
final_df_m = read.table("weather_data/final_df_non_linear.csv",
                        header = TRUE,
                        sep = ",")

#remove index
final_df_mx = final_df_m[, -1]

#generate Date
final_df_mx$DATE =  as.POSIXct(final_df_mx$DATE)

#create pivot table
final_df_mod  = pivot_longer(final_df_mx,
                             -"DATE",
                             names_to = "Method",
                             values_to = "Temperature")

#plot final result and compare methods
ggplot(data = final_df_mod, aes(x = DATE, y = Temperature
                                , colour = Method)) +
  geom_line(lwd = 1.3) +
  labs(x = "Date", y = "Temperature (C°)") +
  ggtitle("1 to 5 April 2019  Zuelpich") +
  scale_color_manual(values = c("red", "darkgreen", "darkblue")) +
  #facet_wrap(vars(Method)) +
  theme_bw(base_size = 15)

```



### Getting Temperature Data

### Task 1 

##### Choose a location of interest and find the 25 closest weather stations using the handle_gsod function

```{r, echo= TRUE}
# 
# station_list_poland = handle_gsod(action="list_stations",
#                            location=c(16.5,51.39),
#                            time_interval=c(1990,2020))
# kable(station_list_poland[1:10,]) %>% kable_styling("striped", position = "left", font_size = 10)

# write.csv(station_list_poland,"weather_data/Poland_station_list.csv",row.names=FALSE)

list_poland_weather = read.table("weather_data/Poland_station_list.csv", header = TRUE, sep=",")
kable(list_poland_weather[1:10,]) %>% kable_styling("striped", position = "left", font_size = 10)
```

### Task 2 
##### Download weather data for the most promising station on the list

Get weather data from LESZNO
```{r, echo = TRUE, message=FALSE, warning=FALSE}
# weather_poland_leszno <- handle_gsod(
#   action = "download_weather",
#   location = station_list_poland$chillR_code[7],
#   time_interval = c(1990, 2020)
# )
# kable(weather_poland_leszno[[1]][[2]][1:10, ]) %>%
#   kable_styling("striped", position = "left", font_size = 10)

#write.csv(weather_poland_leszno[[1]][[2]],"weather_data/Poland_leszno_weather.csv",row.names=FALSE)

weather_poland_leszno_place = read.table("weather_data/Poland_leszno_weather.csv", header = TRUE, sep=",")
kable(weather_poland_leszno_place[1:10, ]) %>%
   kable_styling("striped", position = "left", font_size = 10)

```

### Task 3
##### Convert the weather data into chillR format

```{r}
# weather_pl <- weather_poland_leszno$LESZNO[[2]]
# cleaned_weather_pl <- handle_gsod(weather_pl)

# kable(cleaned_weather_pl[1:20,]) %>%
#   kable_styling("striped", position = "left", font_size = 10)

#write.csv(cleaned_weather_pl,"weather_data/Poland_leszno_chillR_weather.csv",row.names=FALSE)

cleaned_weather_pl_leszno = read.table("weather_data/Poland_leszno_chillR_weather.csv", header = TRUE, sep = ",")

kable(cleaned_weather_pl_leszno[1:10, ]) %>%
   kable_styling("striped", position = "left", font_size = 10)
```


